#!/usr/bin/env python3
# -*- coding: utf-8 -*-

__title__ = "eshell"
__description__ = "Elasticsearch API available via Python interactive shell."
__url__ = "https://github.com/nfsec/eshell"
__version__ = "0.7.6.2"
__license__ = "Apache License (2.0)"
__author__ = "Patryk Krawaczyński <agresor@nfsec.pl>"
__help__ = "Help menu descriptions are from the official Elasticsearch documentation: " \
           "https://www.elastic.co/guide/index.html"

import os
import re
import sys
import ssl
import cmd
import math
import json
import socket
import atexit
import getpass
import argparse
import operator
import readline
import warnings
import requests
import traceback
import subprocess
import elasticsearch
import logging.handlers


# little helpers
class BColors:
    """
    Colors for terminal
    """
    HEADER = "\033[95m"
    OKBLUE = "\033[94m"
    OKGREEN = "\033[92m"
    WARNING = "\033[93m"
    FAIL = "\033[91m"
    ENDC = "\033[0m"
    BOLD = "\033[1m"
    UNDERLINE = "\033[4m"


def error():
    """
    Print error and traceback.
    """
    print(format(BColors.FAIL))
    print("-" * 60)
    print(traceback.print_exc(file=sys.stderr, limit=1))
    print("-" * 60)
    print(format(BColors.ENDC))


def isopen(ip, port):
    """
    Check if address have open port.
    """
    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    s.settimeout(1)
    try:
        s.connect((ip, port))
        s.settimeout(None)
        s.shutdown(2)
        print("Connected to: {0} on port: {1}".format(str(ip), str(port)))
        return True
    except socket.error as s_err:
        print("Problem with connection to: {0} on port: {1}. Error code:".format(str(ip), str(port)), s_err)
        return False


def check_hostname(hostname):
    """
    Check if DNS address is valid one.
    """
    try:
        socket.gethostbyname(hostname)
        return True
    except socket.error:
        return False


def check_ip(ip):
    """
    Check if IP address is valid one.
    """
    try:
        socket.inet_aton(ip)
        return True
    except socket.error:
        return False


def check_env(directory):
    """
    Check and create environment directory and files
    """
    log_file = os.path.expanduser(directory + "/es.log")
    history_file = os.path.expanduser(directory + "/history")
    try:
        if not os.path.exists(os.path.expanduser(directory)):
            os.makedirs(os.path.expanduser(directory), exist_ok=True)
        if not os.path.exists(history_file):
            f = open(history_file, "w+")
            f.write("_HiStOrY_V2_\n\n")
            f.close()
        return history_file, log_file
    except Exception:
        error()


def commandlist(subcommand):
    """
    Return command list from menu.
    """
    commands = []
    for i in dir(subcommand):
        if i.startswith("do_"):
            commands.append(i.replace("do_", ""))
    return commands


def pretty_print(dictionary, indent=0):
    """
    Pretty print all the complexities.
    """
    for k, v in sorted(dictionary.items()):
        if type(v) == dict:
            if len(v) == 0:
                print(" " * indent, str(k) + ": {empty}")
            else:
                print(" " * indent, str(k) + ": ")
                pretty_print(v, indent + len(k) + 1)
        elif type(v) == list:
            if len(v) == 0:
                print(" " * indent, str(k) + ": [empty]")
            elif type(v[0]) == dict:
                print(" " * indent, str(k) + ": ")
                for x in v:
                    pretty_print(x, indent + len(k) + 1)
            else:
                print(" " * indent, str(k) + ": " + str.join(", ", v))
        else:
            print(" " * indent, str(k) + ": " + str(v))


def parse_string(string):
    """
    Convert string in format: key=value to dictionary: {'key': 'value'}
    """
    return dict(i.split("=") for i in string.split())


def parse_list(list_string):
    """
    Convert list in format: ['key=value'] to directory: {'key': 'value'}
    """
    return dict(map(lambda s: s.split('='), list_string))


def less(text):
    """
    Filter long text with the <less> tool
    """
    try:
        pager = subprocess.Popen(["less", "-F", "-R", "-S", "-X", "-K", "-N"], stdin=subprocess.PIPE, stdout=sys.stdout)
        for line in text:
            pager.stdin.write(line.encode("utf-8"))
        pager.stdin.close()
        pager.wait()
    except IOError:
        print("Exiting...")
    except KeyboardInterrupt:
        print("Exiting...")


def convert_size(bytes):
    """
    Convert bytes to human-readable unit.
    """
    if bytes == 0:
        return "0B"
    size_name = ("B", "KB", "MB", "GB", "TB", "PB", "EB", "ZB", "YB")
    i = int(math.floor(math.log(bytes, 1024)))
    p = math.pow(1024, i)
    s = round(bytes / p, 2)
    return "{0} {1}".format(s, size_name[i])


# autocomplete functions
def indexlist():
    indices = []
    for i in es.cat.indices(h="index").split("\n"):
        if i:
            indices.append(i.replace(" ", ""))
    return indices


def nodelist():
    nodes = []
    for i in es.cat.nodes(h="name").split("\n"):
        if i:
            nodes.append(i)
    return nodes


# elasticsearch main-console
class ES(cmd.Cmd):
    intro = "{0}\n### Welcome to elasticsearch shell console!\n### For more information, type \"help\" or \"?\".\n" \
            "### Session will be logged to ~/.e7/es.log.\n" \
            "### Command history will be saved to ~/.e7/history.\n{1}".format(BColors.BOLD, BColors.ENDC)
    prompt = "e7:~$ "
    ruler = "-"
    doc_header = "Available commands (type: help <command>):"

    def default(self, line):
        """
        Called on an input line when the command prefix is not recognized.
        In that case we execute the line as Python code.
        """
        try:
            exec(line) in self._locals, self._globals
        except NameError:
            print("Command {0} not found.".format(line))
        except SyntaxError:
            print("Command not found or invalid syntax.")
        except KeyboardInterrupt:
            print("Detected Ctrl+D. Exiting...")
        except Exception:
            error()

    def preloop(self):
        """
        Initialization before prompting user for commands.
        """
        self._history = []
        self._locals = {}
        self._globals = {}

    def precmd(self, line):
        """
        This method is called after the line has been input but before
        it has been interpreted. If you want to modify the input line
        before execution (for example, variable substitution) do it here.
        """
        self._history += [line.strip()]
        return line

    def postloop(self):
        """
        Take care of any unfinished business.
        """
        cmd.Cmd.postloop(self)
        print("Exiting...")

    def postcmd(self, stop, line):
        """
        If you want to stop the console, return something that evaluates to true.
        If you want to do some post command processing, do it here.
        """
        return stop

    def emptyline(self):
        """
        Do nothing on empty line input.
        """
        pass

    def do_prompt(self, arg):
        """
        Change console prompt.
        $ prompt [new prompt] - set new prompt.
        """
        self.prompt = "{0}:~$ ".format(arg)

    def do_help(self, arg):
        """
        Get help on commands:
        'help' or '?' with no arguments prints a list of commands for which help is available
        'help [command]' or '? [command]' gives help on [command]
        """
        cmd.Cmd.do_help(self, arg)

    def do_history(self, arg):
        """
        Print a list of commands that have been entered into console.
        """
        print(self._history)

    def do_history_file(self, arg):
        """
        Print a list of commands that have been recorded into history file.
        $ history_file 10 - show last 10 commands.
        $ history_file - show all commands.
        """
        if arg:
            history_length = readline.get_current_history_length()
            for i in (range((history_length - int(arg)), history_length)):
                print(readline.get_history_item(i + 1))
        else:
            for i in range(readline.get_current_history_length()):
                print(readline.get_history_item(i + 1))

    def do_history_search(self, arg):
        """
        Search for [term] in history file.
        $ history_search [term]
        """
        for i in (range(readline.get_current_history_length())):
            if re.search(arg, str(readline.get_history_item(i + 1))):
                print(readline.get_history_item(i + 1))

    def do_clear(self, arg):
        """
        Clear the screen.
        """
        os.system("clear")

    def do_shell(self, line):
        """
        Pass command to a system shell when line begins with '!'
        """
        print("Running shell command: {0}\n".format(line))
        sub_cmd = subprocess.Popen(line, shell=True, stdout=subprocess.PIPE)
        output = sub_cmd.communicate()[0].decode("utf-8")
        print(output)
        self.last_output = output

    def do_echo(self, line):
        """
        Print the input, replacing '$out' with the output of the last shell command.
        $ echo $out - print last output for shell command.
        """
        print(line.replace('$out', self.last_output))

    def do_quit(self, arg):
        """
        Quits from the console.
        """
        return True

    def do_exit(self, arg):
        """
        Exits from the console.
        """
        return True

    def do_EOF(self, line):
        """
        Exit on system end of file character (Ctrl+D).
        """
        return True

    def do_show(self, arg):
        """
        Enter to cluster information submenu.
        """
        show_cli = Show()
        show_cli.cmdloop()

    def do_exec(self, arg):
        """
        Enter to cluster execution submenu.
        """
        exec_cli = Exec()
        exec_cli.cmdloop()


# elasticsearch show-console
class Show(cmd.Cmd):
    intro = "\n{0}### Entering to cluster information menu!\n### For more information, type \"help\" or \"?\".\n{1}". \
        format(BColors.BOLD, BColors.ENDC)
    prompt = "es7:show~$ "
    ruler = "-"
    doc_header = "Available commands (type: help <command>):"

    def default(self, line):
        """
        Called on an input line when the command prefix is not recognized.
        In that case we execute the line as Python code.
        """
        try:
            exec(line) in self._locals, self._globals
        except NameError:
            print("Command {0} not found.".format(line))
        except SyntaxError:
            print("Command not found or invalid syntax.")
        except KeyboardInterrupt:
            print("Detected Ctrl+D. Exiting...")
        except Exception:
            error()

    def preloop(self):
        """
        Initialization before prompting user for commands.
        """
        cmd.Cmd.preloop(self)
        self._history = []
        self._locals = {}
        self._globals = {}

    def precmd(self, line):
        """
        This method is called after the line has been input but before
        it has been interpreted. If you want to modify the input line
        before execution (for example, variable substitution) do it here.
        """
        self._history += [line.strip()]
        return line

    def postloop(self):
        """
        Take care of any unfinished business.
        """
        cmd.Cmd.postloop(self)
        print("Exiting...")

    def postcmd(self, stop, line):
        """
        If you want to stop the console, return something that evaluates to true.
        If you want to do some post command processing, do it here.
        """
        return stop

    def emptyline(self):
        """
        Do nothing on empty line input.
        """
        pass

    def do_prompt(self, arg):
        """
        Change console prompt.
        $ prompt [new prompt] - set new prompt.
        """
        self.prompt = "{0}:~$ ".format(arg)

    def do_help(self, arg):
        """
        Get help on commands:
        'help' or '?' with no arguments prints a list of commands for which help is available
        'help <command>' or '? <command>' gives help on <command>
        """
        cmd.Cmd.do_help(self, arg)

    def do_history(self, arg):
        """
        Print a list of commands that have been entered into console.
        """
        print(self._history)

    def do_history_file(self, arg):
        """
        Print a list of commands that have been recorded into history file.
        $ history_file 10 - show last 10 commands.
        $ history_file - show all commands.
        """
        if arg:
            history_length = readline.get_current_history_length()
            for i in (range((history_length - int(arg)), history_length)):
                print(readline.get_history_item(i + 1))
        else:
            for i in range(readline.get_current_history_length()):
                print(readline.get_history_item(i + 1))

    def do_history_search(self, arg):
        """
        Search for [term] in history file.
        $ history_search [term]
        """
        for i in (range(readline.get_current_history_length())):
            if re.search(arg, str(readline.get_history_item(i + 1))):
                print(readline.get_history_item(i + 1))

    def do_clear(self, arg):
        """
        Clear the screen.
        """
        os.system("clear")

    def do_shell(self, line):
        """
        Pass command to a system shell when line begins with '!'
        """
        print("Running shell command: {0}\n".format(line))
        sub_cmd = subprocess.Popen(line, shell=True, stdout=subprocess.PIPE)
        output = sub_cmd.communicate()[0].decode("utf-8")
        print(output)
        self.last_output = output

    def do_echo(self, line):
        """
        Print the input, replacing '$out' with the output of the last shell command.
        $ echo $out - print last output for shell command.
        """
        print(line.replace("$out", self.last_output))

    def do_quit(self, arg):
        """
        Quits from the console.
        """
        return True

    def do_exit(self, arg):
        """
        Exits from the console.
        """
        return True

    def do_EOF(self, line):
        """
        Exit on system end of file character (Ctrl+D).
        """
        return True

    def do_leave(self, line):
        """
        Leave submenu.
        """
        return True

    def do_exec(self, line):
        """
        Execute command in cluster execution menu.
        """
        Exec().onecmd(line)

    def complete_exec(self, text, line, begidx, endidx):
        """
        Complete commands from exec menu.
        """
        return [i for i in commandlist(Exec()) if i.startswith(text)]

    # elasticsearch script-show-console
    def do_script_context(self, arg):
        """
        Returns all script contexts.
        """
        try:
            print()
            pretty_print(es.get_script_context(), indent=2)
            print()
        except Exception:
            error()

    def do_script_languages(self, arg):
        """
        Returns available script types, languages and contexts.
        """
        try:
            print()
            pretty_print(es.get_script_languages(), indent=2)
            print()
        except Exception:
            error()

    def do_script(self, arg):
        """
        Returns a script.
        $ script id - returns a script with id.
        """
        if arg:
            try:
                print()
                es.get_script(id=arg)
                print()
            except Exception:
                error()
        else:
            print()
            print("Please provide script ID.")
            print()

    # elasticsearch cluster-show-console
    def do_cluster_allocation_explain(self, arg):
        """
        The purpose of the cluster allocation explain API is to provide explanations for shard allocations in the
        cluster.
        $ cluster_allocation_explain (args) - explain the first unassigned shard.
          - include_disk_info=true - returns information about disk usage and shard sizes (default: false).
          - include_yes_decisions=true - returns YES decisions in explanation (default: false).
        """
        try:
            print()
            pretty_print(es.cluster.allocation_explain(params=parse_string(arg)), indent=2)
            print()
        except Exception:
            error()

    def do_cluster_allocation_explain_shard(self, arg):
        """
        $ cluster_allocation_explain [index] [shard] [true/false] (args) - specify the index and shard id of the
          shard you would like a explanation for, as well as the primary flag to indicate whether to explain
          the primary shard for the given shard id or one of its replica shards. These three request parameters
          are required.
          * [index] -  specifies the name of the index that you would like an explanation for.
          * [shard] -  specifies the ID of the shard that you would like an explanation for.
          * [true/false] -  if true, returns explanation for the primary shard for the given shard ID.
          - include_disk_info=true - returns information about disk usage and shard sizes (default: false).
          - include_yes_decisions=true - returns YES decisions in explanation (default: false).
        """
        argv = arg.split()
        if len(argv) < 3:
            print()
            print("Please provide [index] name, [shard] and [true] or [false] if primary.")
            print()
        else:
            try:
                payload = '{{ "index": "{0}", "shard": {1}, "primary": {2} }}'.format(str(argv[0]), str(argv[1]),
                                                                                      str(argv[2]))
                print()
                pretty_print(es.cluster.allocation_explain(body=payload, params=(parse_list(argv[3:]))))
                print()
            except Exception:
                error()

    def do_cluster_repositories(self, arg):
        """
        The repositories command shows the snapshot repositories registered in the cluster.
        """
        try:
            print()
            print(es.cat.repositories(v=True, s="id"))
        except Exception:
            error()

    def do_cluster_snapshots(self, arg):
        """
        The cluster_snapshots command shows all snapshots that belong to a specific repository.
        $ cluster_snapshots [repository_name] - show information about each snapshot in repository.
        """
        if arg:
            try:
                print()
                print(es.cat.snapshots(repository=arg, ignore_unavailable=True, v=True, s="id"))
            except Exception:
                error()
        else:
            print()
            print("Please provide name of repository to show its snapshots. ")
            print("To find a list of available repositories to query, the command 'cluster_repositories' can be used.")
            print()

    def do_cluster_ping(self, arg):
        """
        Returns 'UP' if the cluster is up, 'DOWN' otherwise.
        """
        try:
            if es.ping():
                print("\nUP!\n")
            else:
                print("\nDOWN!\n")
        except Exception:
            error()

    def do_cluster_info(self, arg):
        """
        Get the basic info from the current cluster.
        """
        try:
            print()
            pretty_print(es.info(), indent=2)
            print()
        except Exception:
            error()

    def do_cluster_master(self, arg):
        """
        Displays the master’s node ID, bound IP address, and node name.
        """
        try:
            print()
            print(es.cat.master(v=True))
        except Exception:
            error()

    def do_cluster_health(self, arg):
        """
        Get a very simple status on the health of the cluster.
        $ cluster_health - show cluster health.
        $ cluster_health [table] - one-line representation of the same information from cluster_health.
        """
        try:
            if arg == "table":
                print()
                print(es.cat.health(v=True))
            else:
                print()
                pretty_print(es.cluster.health(level="cluster"), indent=2)
                print()
        except Exception:
            error()

    def do_cluster_tasks(self, arg):
        """
        Show all pending cluster tasks which have not yet been executed.
        $ cluster_tasks - show all tasks.
        $ cluster_tasks urgent - show urgent tasks.
        $ cluster_tasks high - show high tasks.
        $ cluster_tasks normal - show normal tasks.
        """
        try:
            task_list = es.cat.pending_tasks(v=True)
            if arg in ["urgent", "high", "normal"]:
                print()
                print(task_list.split("\n")[0])
                for line in task_list.split("\n"):
                    if arg.upper() in line:
                        print(line)
                print()
            else:
                print()
                less(es.cat.pending_tasks())
                print()
        except Exception:
            error()

    def do_cluster_tasks_stats(self, arg):
        """
        Show cluster tasks statistics.
        """
        task_list = requests.get("{0}/_cat/pending_tasks?v=True".format(ehost))
        ustats = re.compile("URGENT")
        umatch = ustats.findall(task_list.content.decode("utf-8"))
        hstats = re.compile("HIGH")
        hmatch = hstats.findall(task_list.content.decode("utf-8"))
        nstats = re.compile("NORMAL")
        nmatch = nstats.findall(task_list.content.decode("utf-8"))
        print("Tasks statistics: URGENT: {0} HIGH: {1} NORMAL: {2}".format(str(len(umatch)), str(len(hmatch)), str(
            len(nmatch))))

    def do_cluster_settings(self, arg):
        """
        Get current cluster settings.
        $ cluster_settings - get cluster custom settings.
        """
        try:
            print()
            pretty_print(es.cluster.get_settings(flat_settings=True), indent=2)
            print()
        except Exception:
            error()

    def do_cluster_settings_with_defaults(self, arg):
        """
        Get current cluster settings.
        $ cluster_settings_with_defaults - get cluster settings with default values.
        """
        try:
            print()
            pretty_print(es.cluster.get_settings(flat_settings=True, include_defaults=True), indent=2)
            print()
        except Exception:
            error(arg)

    def do_cluster_stats(self, arg):
        """
        The Cluster stats allows to retrieve statistics from a cluster wide perspective.
        $ cluster_stats [node_id] - show stats for node_id.
        $ cluster_stats _all - show stats for all nodes.
        $ cluster_stats _local - show stats only for local node.
        $ cluster_stats _master - show stats for the currently-elected master node.
        $ cluster_stats master:true/false - show/hide stats for all master-eligible nodes.
        $ cluster_stats data:true/false - show/hide stats for all data nodes.
        $ cluster_stats ingest:true/false - show/hide for all ingest nodes.
        $ cluster_stats coordinating_only:true/false - show/hide for all coordinating-only nodes.
        """
        if arg:
            try:
                print()
                pretty = es.cluster.stats(node_id=arg)
                pretty_print(pretty, indent=7)
                print()
            except Exception:
                error()
        else:
            try:
                print()
                pretty = es.cluster.stats(human=True)
                print("cluster_name: {0}".format(str(pretty["cluster_name"])))
                print("status: {0}".format(str(pretty["status"])))
                print("timestamp: {0}".format(str(pretty["timestamp"])))
                print("_nodes")
                pretty_print(pretty["_nodes"], indent=7)
                print("nodes:")
                pretty_print(pretty["nodes"], indent=6)
                print("indices:")
                pretty_print(pretty["indices"], indent=8)
                print()
            except Exception:
                error()

    def do_cluster_state(self, arg):
        """
        Shows the cluster state.
        $ cluster_state - returns all metadata about the state of the cluster.
        $ cluster_state [metrics] [target] - returns filtered part of the response.
          [metrics]:
          - _all - show all metrics.
          - blocks - show the blocks part of the response.
          - master_node - shows the elected master_node part of the response.
          - metadata - shows the metadata part of the response.
          - nodes - shows the node part of the response.
          - routing_nodes - shows the routing_nodes part of the response.
          - routing_table - shows the routing_table part of the response.
          - version - shows the cluster state version.
          [target]:
          - comma-separated list of indices or index aliases used to limit the request.
          - wildcard expressions (*) are supported.
          - to target all data streams and indices in a cluster, omit this parameter or use _all or *.
        """
        if arg:
            argv = arg.split()
            if len(argv) != 2:
                print()
                print("Please provide [metrics] and [target]")
                print()
            else:
                try:
                    print()
                    pretty_print(es.cluster.state(metric=argv[0], index=argv[1], flat_settings=True), indent=2)
                    print()
                except Exception:
                    error()
        else:
            try:
                print()
                pretty_print(es.cluster.state(metric="_all", flat_settings=True), indent=2)
                print()
            except Exception:
                error()

    def do_cluster_state_size(self, arg):
        """
        Show cluster state size in MB
        """
        try:
            state_size = requests.get("{0}/_cluster/state/_all".format(ehost), stream=True)
            print()
            print("Approximately: " + convert_size(len(state_size.content)))
            print()
        except Exception:
            error()

    def do_cluster_remote(self, arg):
        """
        This command returns connection and endpoint information keyed to the configured remote cluster alias.

        - seeds - the configured initial seed transport addresses of the remote cluster.
        - http_addresses - the published http addresses of all connected remote nodes.
        - connected - true if there is at least one connection to the remote cluster.
        - num_nodes_connected - the number of connected nodes in the remote cluster.
        - max_connections_per_cluster - the maximum number of connections maintained for the remote cluster.
        - initial_connect_timeout - the initial connect timeout for remote cluster connections.
        - skip_unavailable - whether the remote cluster is skipped in case it is searched through a cross-cluster search
          request but none of its nodes are available.
        - proxy_address - address for remote connections when proxy mode is configured.
        - num_proxy_sockets_connected - number of open socket connections to the remote cluster in proxy mode is
          configured.
        - max_proxy_socket_connections - the maximum number of socket connections to the remote cluster when proxy mode
          is configured.
        """
        try:
            print()
            pretty_print(es.cluster.remote_info())
            print()
        except Exception:
            error()

    # elasticsearch indices-show-console
    def do_indices_recovery(self, arg):
        """
        The indices recovery API provides insight into on-going index shard recoveries.
        $ indices_recovery [index] (args) - recovery status reported for specific indices.
          * [index] - comma-separated list or wildcard expression of index names used to limit the request.
          - active_only=true - the response only includes ongoing shard recoveries.
          - detailed=true - the response includes detailed information about shard recoveries.
          - human=true - statistics are returned in a format suitable for humans.
        """
        argv = arg.split()
        if len(argv) >= 1:
            try:
                print()
                pretty_print(es.indices.recovery(index=argv[0], params=(parse_list(argv[1:]))))
                print()
            except Exception:
                error()
        else:
            print()
            print("Please provide [index] name.")
            print()

    def complete_indices_recovery(self, text, line, begidx, endidx):
        return [i for i in indexlist() if i.startswith(text)]

    def do_indices_head(self, arg):
        """
        Show the [number] of first documents in the [index].
        $ indices_head [index] [number] - show the [number] of first documents in [index].
        """
        argv = arg.split()
        if len(argv) == 2:
            try:
                print()
                print(json.dumps(es.search(index=argv[0], size=argv[1], q='*'), indent=4))
                print()
            except Exception:
                error()
        else:
            print()
            print("Please enter [index] name and [number] of documents.")
            print()

    def complete_indices_head(self, text, line, begidx, endidx):
        return [i for i in indexlist() if i.startswith(text)]

    def do_indices_tail(self, arg):
        """
        Show the [number] of recent documents in the [index].
        $ indices_tail [index] [number] [field] - show the [number] of recent documents in [index] sorted by [field].
        """
        argv = arg.split()
        if len(argv) == 3:
            try:
                print()
                print(json.dumps(es.search(index=argv[0], size=argv[1], q='*', sort=argv[2] + ':desc'), indent=4))
                print()
            except Exception:
                error()
        else:
            print()
            print("Please enter [index] name, [number] of documents and [field] for sorting.")
            print()

    def complete_indices_tail(self, text, line, begidx, endidx):
        return [i for i in indexlist() if i.startswith(text)]

    def do_indices_field_caps(self, arg):
        """
        The field capabilities API allows to retrieve the capabilities of fields among multiple indices.
        $ indices_field_caps [index] [field] - show [field] capabilities in [index].
        """
        argv = arg.split()
        if len(argv) == 2:
            try:
                print()
                pretty_print(
                    es.field_caps(index=argv[0], fields=argv[1], expand_wildcards="all", include_unmapped=True))
                print()
            except Exception:
                error()
        else:
            print()
            print("Please enter [index] and [field] name.")
            print()

    def complete_indices_field_caps(self, text, line, begidx, endidx):
        return [i for i in indexlist() if i.startswith(text)]

    def do_indices_field_termvectors(self, arg):
        """
        Returns information and statistics on terms in the filed of a particular document.
        $ indices_field_termvectors [index] [doc_type] [doc_id] [field] - returns all information and statistics for
                                                                          field in document.
        """
        argv = arg.split()
        if len(argv) == 4:
            try:
                print()
                pretty_print(es.termvectors(index=argv[0], doc_type=argv[1], id=argv[2], fields=argv[3],
                                            offsets=True, payloads=True, positions=True, term_statistics=True,
                                            field_statistics=True))
                print()
            except Exception:
                error()
        else:
            print()
            print("Please enter: [index], [document type], [document id] and [field] name.")
            print()

    def complete_indices_field_termvectors(self, text, line, begidx, endidx):
        return [i for i in indexlist() if i.startswith(text)]

    def do_indices_templates(self, arg):
        """
        The indices_templates command provides information about existing indices templates.
        $ indices_templates [template_name] - show template information in json format.
        $ indices_templates - show all templates for indices.
        """
        if arg:
            try:
                print()
                print(json.dumps(es.indices.get_template(name=arg), indent=4))
                print()
            except Exception:
                error()
        else:
            try:
                print()
                print(es.cat.templates(v=True, s="name"))
            except Exception:
                error()

    def do_indices_mapping(self, arg):
        """
        Retrieve mapping definition of index or index/type.
        $ indices_mapping [index] - show [index] mapping.
        """
        if arg:
            try:
                print()
                pretty = es.indices.get_mapping(index=arg)
                print(json.dumps(pretty, indent=4))
                print()
            except Exception:
                error()
        else:
            print()
            print("Please provide [index] name.")
            print()

    def complete_indices_mapping(self, text, line, begidx, endidx):
        return [i for i in indexlist() if i.startswith(text)]

    def do_indices_field_mapping(self, arg):
        """
        Retrieve mapping definition of a specific field.
        $ indices_field_mapping [index] [field] - show [field] mapping in [index].
        """
        argv = arg.split()
        if len(argv) == 2:
            try:
                print()
                print(json.dumps(es.indices.get_field_mapping(index=argv[0], fields=argv[1], expand_wildcards="all"),
                                 indent=4))
                print()
            except Exception:
                error()
        else:
            print()
            print("Please enter [index] and [field] name.")
            print()

    def complete_indices_field_mapping(self, text, line, begidx, endidx):
        return [i for i in indexlist() if i.startswith(text)]

    def do_indices_stats(self, arg):
        """
        Use the index stats API to get high-level aggregation and statistics for an index.
        $ indices_stats_docs [index] [metric]- show [metric] stats for [index].
          metrics:
          - _all - return all statistics.
          - completion - completion suggester statistics.
          - docs - number of documents and deleted docs, which have not yet merged out
            (index refreshes can affect this statistic).
          - fielddata - fielddata statistics.
          - flush - flush statistics.
          - get - get statistics, including missing stats.
          - indexing - indexing statistics.
          - merge - merge statistics.
          - query_cache - query cache statistics.
          - refresh - refresh statistics.
          - request_cache - shard request cache statistics.
          - search - search statistics including suggest statistics.
          - segments - memory use of all open segments.
          - store - size of the index in byte units.
          - suggest - suggester statistics.
          - translog - translog statistics.
          - warmer - warmer statistics.
        """
        argv = arg.split()
        if len(argv) == 2:
            try:
                print()
                pretty_print(es.indices.stats(index=argv[0], level="indices", metric=argv[1], expand_wildcards="all",
                                              human=True), indent=2)
                print()
            except Exception:
                error()
        else:
            print()
            print("Please enter [index] and [metric] name.")
            print()

    def complete_indices_stats(self, text, line, begidx, endidx):
        return [i for i in indexlist() if i.startswith(text)]

    def do_indices_size(self, arg):
        """
        Show indices size statistics.
        """
        try:
            index_list = es.cat.indices(h="index,pri.store.size", bytes="b")
            index_temp = []
            for text_line in index_list.split():
                index_temp.append(text_line)
            index_dict = dict(index_temp[i:i + 2] for i in range(0, len(index_temp), 2))
            index_dict = {str(k): int(v) for k, v in index_dict.items()}
            index_sort = sorted(index_dict.items(), key=operator.itemgetter(1))
            almost_1mb = []
            almost_10mb = []
            almost_100mb = []
            almost_1gb = []
            almost_10gb = []
            almost_100gb = []
            almost_other = []
            for item in index_sort:
                if item[1] <= 1000000:
                    almost_1mb.append(item)
                elif item[1] <= 10000000:
                    almost_10mb.append(item)
                elif item[1] <= 100000000:
                    almost_100mb.append(item)
                elif item[1] <= 1000000000:
                    almost_1gb.append(item)
                elif item[1] <= 10000000000:
                    almost_10gb.append(item)
                elif item[1] <= 100000000000:
                    almost_100gb.append(item)
                elif item[1] >= 100000000000:
                    almost_other.append(item)
            print()
            print(
                "i <= 1.MB: {0} | i <= 10.MB: {1} | i <= 100.MB: {2} | i <= 1.GB: {3} | i <= 10.GB: {4} | i <= "
                "100.GB: {5} | i >= 100.GB: {6}".format(
                    str(len(almost_1mb)), str(
                        len(almost_10mb)), str(len(almost_100mb)), str(
                        len(almost_1gb)), str(len(almost_10gb)), str(
                        len(almost_100gb)), str(len(almost_other))))
            print()
        except Exception:
            error()

    def do_indices_settings(self, arg):
        """
        Retrieve settings for one or more (or all) indices.
        - indices_settings [index] - show settings for [index].
        - indices_settings - show settings for all indices (default).
        """
        if arg:
            try:
                print()
                pretty_print(es.indices.get_settings(index=arg, flat_settings=True), indent=2)
                print()
            except Exception:
                error()
        else:
            try:
                print()
                pretty_print(es.indices.get_settings(flat_settings=True), indent=2)
                print()
            except Exception:
                error()

    def complete_indices_settings(self, text, line, begidx, endidx):
        return [i for i in indexlist() if i.startswith(text)]

    def do_indices_status(self, arg):
        """
        Show indices state statistics.
        """
        try:
            index_list = es.cat.indices(v=True, h="health")
            rstats = re.compile("red")
            rmatch = rstats.findall(index_list)
            ystats = re.compile("yellow")
            ymatch = ystats.findall(index_list)
            gstats = re.compile("green")
            gmatch = gstats.findall(index_list)
            print("Indices states: RED: {0} YELLOW: {1} GREEN: {2}".format(str(len(rmatch)), str(len(ymatch)), str(
                len(gmatch))))
        except Exception:
            error()

    def do_indices_exists(self, arg):
        """
        Return a information indicating whether given index exists.
        $ indices_exists [index] - a name of index to check (default).
        """
        if arg:
            print()
            try:
                if es.indices.exists(index=arg):
                    print("{0} exists.".format(arg))
                    print()
                else:
                    print("{0} don't exists".format(arg))
                    print()
            except Exception:
                error()
        else:
            print()
            print("No indices specified.")
            print()

    def complete_indices_exists(self, text, line, begidx, endidx):
        return [i for i in indexlist() if i.startswith(text)]

    def do_indices_segments(self, arg):
        """
        The segments command is the detailed view of Lucene segments per index.
        $ indices_segments [index] - show segments of the index.
        $ indices_segments  - show segments of all indices (default).
        """
        if arg:
            try:
                print()
                less(es.cat.segments(index=arg, v=True, s="index"))
                print()
            except Exception:
                error()
        else:
            try:
                print()
                less(es.cat.segments(v=True, s="index"))
                print()
            except Exception:
                error()

    def complete_indices_segments(self, text, line, begidx, endidx):
        return [i for i in indexlist() if i.startswith(text)]

    def do_indices_segments_verbose(self, arg):
        """
        Provide low level segments information that a Lucene index (shard level) is built with.
        $ indices_segments_verbose [index] - show segments of the index.
        $ indices_segments_verbose - show segments off all indices (default).
        """
        if arg:
            try:
                print()
                pretty_print(es.indices.segments(index=arg, verbose=True), indent=2)
                print()
            except Exception:
                error()
        else:
            try:
                print()
                pretty_print(es.indices.segments(verbose=True), indent=2)
                print()
            except Exception:
                error()

    def complete_indices_segments_verbose(self, text, line, begidx, endidx):
        return [i for i in indexlist() if i.startswith(text)]

    def do_indices_metadata(self, arg):
        """
        Shows the metadata part of the response. If you supply a comma separated list of indices,
        the returned output will only contain metadata for these indices.
        $ indices_metadata [index] - show metadata of <index>.
        $ indices_metadata - show metadata of all indices (default).
        """
        if arg:
            try:
                print()
                pretty_print(es.cluster.state(metric="metadata", index=arg, flat_settings=True), indent=2)
                print()
            except Exception:
                error()
        else:
            try:
                print()
                pretty_print(es.cluster.state(metric="metadata", flat_settings=True), indent=2)
                print()
            except Exception:
                error()

    def complete_indices_metadata(self, text, line, begidx, endidx):
        return [i for i in indexlist() if i.startswith(text)]

    do_cluster_state_metadata = do_indices_metadata

    def do_indices(self, arg):
        """
         The indices command provides a cross-section of each index.
         $ indices [index] - show information about [index].
         $ indices - show information about all indices (default).
        """
        if arg:
            try:
                print()
                print(es.cat.indices(s="index", v=True, include_unloaded_segments=True, index=arg))
            except Exception:
                error()
        else:
            try:
                print()
                less(es.cat.indices(s="index", v=True, include_unloaded_segments=True))
                print()
            except Exception:
                error()

    def complete_indices(self, text, line, begidx, endidx):
        return [i for i in indexlist() if i.startswith(text)]

    def do_indices_by(self, arg):
        """
        Which index has the largest X sorted by Y?
        $ indices_by dc [asc/desc] dc [index] - show and sort indices with largest number of documents.

        health                           | h                              | current health status
        status                           | s                              | open/close status
        index                            | i,idx                          | index name
        uuid                             | id,uuid                        | index uuid
        pri                              | p,shards.primary,shardsPrimary | number of primary shards
        rep                              | r,shards.replica,shardsReplica | number of replica shards
        docs.count                       | dc,docsCount                   | available docs
        docs.deleted                     | dd,docsDeleted                 | deleted docs
        creation.date                    | cd                             | index creation date (millisecond value)
        creation.date.string             | cds                            | index creation date (as string)
        store.size                       | ss,storeSize                   | store size of primaries & replicas
        completion.size                  | cs,completionSize              | size of completion
        fielddata.memory_size            | fm,fielddataMemory             | used fielddata cache
        fielddata.evictions              | fe,fielddataEvictions          | fielddata evictions
        query_cache.memory_size          | qcm,queryCacheMemory           | used query cache
        query_cache.evictions            | qce,queryCacheEvictions        | query cache evictions
        request_cache.memory_size        | rcm,requestCacheMemory         | used request cache
        request_cache.evictions          | rce,requestCacheEvictions      | request cache evictions
        request_cache.hit_count          | rchc,requestCacheHitCount      | request cache hit count
        request_cache.miss_count         | rcmc,requestCacheMissCount     | request cache miss count
        flush.total                      | ft,flushTotal                  | number of flushes
        flush.total_time                 | ftt,flushTotalTime             | time spent in flush
        get.current                      | gc,getCurrent                  | number of current get ops
        get.time                         | gti,getTime                    | time spent in get
        get.total                        | gto,getTotal                   | number of get ops
        get.exists_time                  | geti,getExistsTime             | time spent in successful gets
        get.exists_total                 | geto,getExistsTotal            | number of successful gets
        get.missing_time                 | gmti,getMissingTime            | time spent in failed gets
        get.missing_total                | gmto,getMissingTotal           | number of failed gets
        indexing.delete_current          | idc,indexingDeleteCurrent      | number of current deletions
        indexing.delete_time             | idti,indexingDeleteTime        | time spent in deletions
        indexing.delete_total            | idto,indexingDeleteTotal       | number of delete ops
        indexing.index_current           | iic,indexingIndexCurrent       | number of current indexing ops
        indexing.index_time              | iiti,indexingIndexTime         | time spent in indexing
        indexing.index_total             | iito,indexingIndexTotal        | number of indexing ops
        indexing.index_failed            | iif,indexingIndexFailed        | number of failed indexing ops
        merges.current                   | mc,mergesCurrent               | number of current merges
        merges.current_docs              | mcd,mergesCurrentDocs          | number of current merging docs
        merges.current_size              | mcs,mergesCurrentSize          | size of current merges
        merges.total                     | mt,mergesTotal                 | number of completed merge ops
        merges.total_docs                | mtd,mergesTotalDocs            | docs merged
        merges.total_size                | mts,mergesTotalSize            | size merged
        merges.total_time                | mtt,mergesTotalTime            | time spent in merges
        refresh.total                    | rto,refreshTotal               | total refreshes
        refresh.time                     | rti,refreshTime                | time spent in refreshes
        refresh.listeners                | rli,refreshListeners           | number of pending refresh listeners
        search.fetch_current             | sfc,searchFetchCurrent         | current fetch phase ops
        search.fetch_time                | sfti,searchFetchTime           | time spent in fetch phase
        search.fetch_total               | sfto,searchFetchTotal          | total fetch ops
        search.open_contexts             | so,searchOpenContexts          | open search contexts
        search.query_current             | sqc,searchQueryCurrent         | current query phase ops
        search.query_time                | sqti,searchQueryTime           | time spent in query phase
        search.query_total               | sqto,searchQueryTotal          | total query phase ops
        search.scroll_current            | scc,searchScrollCurrent        | open scroll contexts
        search.scroll_time               | scti,searchScrollTime          | time scroll contexts held open
        search.scroll_total              | scto,searchScrollTotal         | completed scroll contexts
        segments.count                   | sc,segmentsCount               | number of segments
        segments.memory                  | sm,segmentsMemory              | memory used by segments
        segments.index_writer_memory     | siwm,segmentsIndexWriterMemory | memory used by index writer
        segments.version_map_memory      | svmm,segmentsVersionMapMemory  | memory used by version map
        segments.fixed_bitset_memory     | sfbm,fixedBitsetMemory         | memory used by fixed bit sets for nested
                                                                            object field types and type filters for
                                                                            types referred in _parent fields
        warmer.current                   | wc,warmerCurrent               | current warmer ops
        warmer.total                     | wto,warmerTotal                | total warmer ops
        warmer.total_time                | wtt,warmerTotalTime            | time spent in warmers
        suggest.current                  | suc,suggestCurrent             | number of current suggest ops
        suggest.time                     | suti,suggestTime               | time spend in suggest
        suggest.total                    | suto,suggestTotal              | number of suggest ops
        memory.total                     | tm,memoryTotal                 | total used memory
        """
        argv = arg.split()
        if len(argv) == 4:
            try:
                print()
                less(es.cat.indices(s=argv[0] + ":" + argv[1], v=True, h="index," + argv[2], index=argv[3]))
                print()
            except Exception:
                error()
        else:
            print()
            print("Please enter value to sort on [asc/desc] and value to display. Use help for possible values.")
            print()

    def do_indices_green(self, arg):
        """
        The indices_green command provides a cross-section of each index in green health status.
        $ indices [index] - show information about [index].
        $ indices - show information about all indices (default).
        """
        if arg:
            try:
                print()
                print(es.cat.indices(s="index", v=True, index=arg, health="green"))
            except Exception:
                error()
        else:
            try:
                print()
                print(es.cat.indices(s="index", v=True, health="green"))
            except Exception:
                error()

    def complete_indices_green(self, text, line, begidx, endidx):
        return [i for i in indexlist() if i.startswith(text)]

    def do_indices_yellow(self, arg):
        """
        The indices_yellow command provides a cross-section of each index in yellow health status.
        $ indices [index] - show information about [index].
        $ indices - show information about all indices (default).
        """
        if arg:
            try:
                print()
                print(es.cat.indices(s="index", v=True, index=arg, health="yellow"))
            except Exception:
                error()
        else:
            try:
                print()
                print(es.cat.indices(s="index", v=True, health="yellow"))
            except Exception:
                error()

    def complete_indices_yellow(self, text, line, begidx, endidx):
        return [i for i in indexlist() if i.startswith(text)]

    def do_indices_red(self, arg):
        """
        The indices_red command provides a cross-section of each index in red health status.
        $ indices [index] - show information about [index].
        $ indices - show information about all indices (default).
        """
        if arg:
            try:
                print()
                print(es.cat.indices(s="index", v=True, index=arg, health="red"))
            except Exception:
                error()
        else:
            try:
                print()
                print(es.cat.indices(s="index", v=True, health="red"))
            except Exception:
                error()

    def complete_indices_red(self, text, line, begidx, endidx):
        return [i for i in indexlist() if i.startswith(text)]

    def do_indices_aliases(self, arg):
        """
        Shows information about currently configured aliases to indices including filter and routing info.
        $ indices_aliases [alias] - [alias] name to return from aliases.
        $ indices_aliases - show all aliases (default).
        """
        if arg:
            try:
                print()
                print(es.cat.aliases(name=arg, v=True))
                print()
            except Exception:
                error()
        else:
            try:
                print()
                print(es.cat.aliases(s="alias", v=True))
                print()
            except Exception:
                error()

    def do_indices_documents(self, arg):
        """
        Indices documents provides quick access to the document count of the entire cluster, or individual indices.
        The document count indicates the number of live documents and does not include deleted documents
        which have not yet been cleaned up by the merge process.
        $ indices_documents [index] - document count in [index].
        $ indices_documents - document count for all indices (default).
        """
        if arg:
            try:
                print()
                print(es.cat.count(index=arg, v=True))
                print()
            except Exception:
                error()
        else:
            try:
                print()
                print(es.cat.count(v=True))
                print()
            except Exception:
                error()

    def complete_indices_documents(self, text, line, begidx, endidx):
        return [i for i in indexlist() if i.startswith(text)]

    def do_indices_routing_table(self, arg):
        """
        Shows indices the routing table part of the response.
        If you supply a comma separated list of indices, the returned
        output will only contain the indices listed.
        $ indices_routing_table [index] - show routing_table of [index].
        $ indices_routing_table - show routing_table of all indices (default).
        """
        if arg:
            try:
                print()
                pretty_print(es.cluster.state(metric="routing_table", index=arg, flat_settings=True), indent=2)
                print()
            except Exception:
                error()
        else:
            try:
                print()
                pretty_print(es.cluster.state(metric="routing_table", flat_settings=True), indent=2)
                print()
            except Exception:
                error()

    def complete_indices_routing_table(self, text, line, begidx, endidx):
        return [i for i in indexlist() if i.startswith(text)]

    do_cluster_state_routing_table = do_indices_routing_table

    def do_indices_health(self, arg):
        """
        Get a very simple status on the health of the indices.
        $ indices_health [index] - show health of [index].
        $ indices_health - show health of all indices (default).
        """
        if arg:
            try:
                print()
                pretty_print(es.cluster.health(level="indices", index=arg), indent=2)
                print()
            except Exception:
                error()
        else:
            try:
                print()
                pretty_print(es.cluster.health(level="indices"), indent=2)
                print()
            except Exception:
                error()

    def complete_indices_health(self, text, line, begidx, endidx):
        return [i for i in indexlist() if i.startswith(text)]

    def do_indices_search_shards(self, arg):
        """
        Returns the indices and shards that a search request would be executed against.
        $ indices_search_shards [index] - show which shards will be searched for [index].
        $ indices_search_shards - show which shards will be searched for all indices (default).
        """
        if arg:
            try:
                print()
                print(json.dumps(es.search_shards(index=arg), indent=4))
                print()
            except Exception:
                error()
        else:
            try:
                print()
                print(json.dumps(es.search_shards(), indent=4))
                print()
            except Exception:
                error()

    def complete_indices_search_shards(self, text, line, begidx, endidx):
        return [i for i in indexlist() if i.startswith(text)]

    # elasticsearch shards-show-console
    def do_shards(self, arg):
        """
        The shards command is the detailed view of what nodes contain which shards.
        $ shards [index] - show shards of [index].
        $ shards - show shards of all indices (default).
        """
        if arg:
            try:
                print()
                print(es.cat.shards(index=arg, v=True, s="node"))
            except Exception:
                error()
        else:
            try:
                print()
                less(es.cat.shards(v=True))
                print()
            except Exception:
                error()

    def complete_shards(self, text, line, begidx, endidx):
        return [i for i in indexlist() if i.startswith(text)]

    def do_shards_store(self, arg):
        """
        Provides store information for shard copies of indices. Store information reports on which
        nodes shards copies exist, the shard copy version, indicating how recent the are, and any
        exceptions encountered while opening the shard index or from earlier engine failure.
        $ shards_store [index] [red|yellow|green] - show shards store information about [index].
        $ shards_store - show shards store information about all indices.
        """
        if arg:
            argv = arg.split()
            if len(argv) != 2:
                print()
                print("Please enter [index] and its [status (red|yellow|green)].")
                print()
            else:
                try:
                    print()
                    print(json.dumps(es.indices.shard_stores(index=argv[0], status=argv[1]), indent=4))
                    print()
                except Exception:
                    error()
        else:
            try:
                print()
                print(json.dumps(es.indices.shard_stores(index="_all", status="all"), indent=4))
                print()
            except Exception:
                error()

    def complete_shards_store(self, text, line, begidx, endidx):
        return [i for i in indexlist() if i.startswith(text)]

    def do_shards_unassigned(self, arg):
        """
        List unassigned shards.
        $ shards_unassigned - show all unassigned shards.
        $ shards_unassinged [regex] - show only unassigned shards matching regex.
        """
        shard_list = es.cat.shards(v=True)
        print()
        print(shard_list.split("\n")[0])
        for line in shard_list.split("\n"):
            if "UNASSIGNED" in line:
                if arg:
                    if re.search(arg, line):
                        print(line)
                else:
                    print(line)
        print()

    def do_shards_relocating(self, arg):
        """
        List relocating shards.
        $ shards_relocating - show all relocating shards.
        $ shards_relocating [regex] - show only relocating shards matching regex.
        """
        shard_list = es.cat.shards(v=True)
        print()
        print(shard_list.split("\n")[0])
        for line in shard_list.split("\n"):
            if "RELOCATING" in line:
                if arg:
                    if re.search(arg, line):
                        print(line)
                else:
                    print(line)
        print()

    def do_shards_initializing(self, arg):
        """
        List initializing shards.
        $ shards_initializing - show all initializing shards.
        $ shards_initializing [regex] - show only initializing shards matching regex.
        """
        shard_list = es.cat.shards(v=True)
        print()
        print(shard_list.split("\n")[0])
        for line in shard_list.split("\n"):
            if "INITIALIZING" in line:
                if arg:
                    if re.search(arg, line):
                        print(line)
                else:
                    print(line)
        print()

    def do_shards_started(self, arg):
        """
        List started shards.
        $ shards_started - show all started shards.
        $ shards_started [regex] - show only started shards matching regex.
        """
        shard_list = es.cat.shards(v=True)
        print()
        print(shard_list.split("\n")[0])
        for line in shard_list.split("\n"):
            if "STARTED" in line:
                if arg:
                    if re.search(arg, line):
                        print(line)
                else:
                    print(line)
        print()

    def do_shards_recovery(self, arg):
        """
        Recovery is a view of shard replication.
        $ shards_recovery [index] - show recovery status of the [index].
        $ shards_recovery - show recovery status of all indices (default).

          index                  | idx   | index name
          shard                  | sh    | shard name
          time                   | ti    | recovery time
          type                   | ty    | recovery type
          stage                  | st    | recovery stage
          source_host            | shost | source host
          source_node            | snode | source node name
          target_host            | thost | target host
          target_node            | tnode | target node name
          repository             | rep   | repository
          snapshot               | snap  | snapshot
          files                  | f     | number of files to recover
          files_recovered        | fr    | files recovered
          files_percent          | fp    | percent of files recovered
          files_total            | tf    | total number of files
          bytes                  | b     | number of bytes to recover
          bytes_recovered        | br    | bytes recovered
          bytes_percent          | bp    | percent of bytes recovered
          bytes_total            | tb    | total number of bytes
          translog_ops           | to    | number of translog ops to recover
          translog_ops_recovered | tor   | translog ops recovered
          translog_ops_percent   | top   | percent of translog ops recovered
        """
        if arg:
            try:
                print()
                print(es.cat.recovery(index=arg, v=True, s="index",
                                      h="idx,sh,ti,ty,st,shost,snode,thost,tnode,rep,snap,f,fr,fp,tf,b,br,bp,tb,to,"
                                        "tor,top"))
            except Exception:
                error()
        else:
            try:
                print()
                less(es.cat.recovery(v=True, s="index",
                                     h="idx,sh,ti,ty,st,shost,snode,thost,tnode,rep,snap,f,fr,fp,tf,b,br,bp,tb,to,"
                                       "tor,top"))
                print()
            except Exception:
                error()

    def complete_shards_recovery(self, text, line, begidx, endidx):
        return [i for i in indexlist() if i.startswith(text)]

    def do_shards_health(self, arg):
        """
        Get a very simple status on the health of the indices shards.
        $ indices_health [index] - show health of index [shards].
        $ indices_health - show health of shards in all indices (default).
        """
        if arg:
            try:
                print()
                pretty_print(es.cluster.health(level="shards", index=arg), indent=2)
                print()
            except Exception:
                error()
        else:
            try:
                print()
                pretty_print(es.cluster.health(level="shards"), indent=2)
                print()
            except Exception:
                error()

    def complete_shards_health(self, text, line, begidx, endidx):
        return [i for i in indexlist() if i.startswith(text)]

    # elasticsearch nodes-show-console
    def do_nodes_allocation(self, arg):
        """
        Allocation provides a snapshot of how shards have located around the cluster and the state of disk usage.
        $ nodes_allocation [name|node_id] - show [node] shards allocation.
        $ nodes_allocation - show shards allocation for all the nodes (default).
        """
        if arg:
            try:
                print()
                print(es.cat.allocation(node_id=arg, v=True))
            except Exception:
                error()
        else:
            try:
                print()
                print(es.cat.allocation(s="node", v=True))
            except Exception:
                error()

    def complete_nodes_allocation(self, text, line, begidx, endidx):
        return [i for i in nodelist() if i.startswith(text)]

    do_nodes_disk = do_nodes_allocation

    def do_nodes_fielddata(self, arg):
        """
        Shows information about currently loaded fielddata on a per-node basis.
        $ nodes_fielddata [field] - show fielddata size for individual <field>.
        $ nodes_fielddata - shows how much heap memory is currently being used by
          fielddata on every data node in the cluster (default).

        """
        if arg:
            try:
                print()
                print(es.cat.fielddata(s="node", v=True, bytes="mb", fields=arg))
            except Exception:
                error()
        else:
            try:
                print()
                print(es.cat.fielddata(s="node", v=True, bytes="mb"))
            except Exception:
                error()

    def do_nodes_attributes(self, arg):
        """
        Shows custom node attributes.
        """
        try:
            print()
            print(es.cat.nodeattrs(s="node", v=True))
        except Exception:
            error()

    def do_nodes_usage(self, arg):
        """
        The cluster nodes usage API allows to retrieve information on the usage
        of features for each node.
        $ nodes_usage [name|node_id] - show information on the usage of [node].
        $ nodes_usage - show information on the usage of all nodes.
        """
        if arg:
            try:
                print()
                pretty_print(es.nodes.usage(node_id=arg, human=True), indent=2)
                print()
            except Exception:
                error()
        else:
            try:
                print()
                pretty_print(es.nodes.usage(human=True), indent=2)
                print()
            except Exception:
                error()

    def complete_nodes_usage(self, text, line, begidx, endidx):
        return [i for i in nodelist() if i.startswith(text)]

    def do_nodes_plugins(self, arg):
        """
        The plugins command provides a view per nodes of running plugins.
        """
        try:
            print()
            print(es.cat.plugins(v=True, s="name", h="name,component,version,description"))
        except Exception:
            error()

    def do_nodes_settings(self, arg):
        """
        Retrieves information about node(s) settings in the cluster.
        $ nodes_settings [name|node_id] - show [node] settings.
        $ node_settings - show all the nodes settings in the cluster (default).

          - build_hash - sort of the last git commit in this release.
          - host - the node's host name.
          - http_address - host and port where primary HTTP connections are accepted.
          - ip - the node's ip address.
          - name - the nodes name.
          - transport_address - host and port where transport HTTP connections are accepted.
          - version - elasticsearch version running on this node.
        """
        if arg:
            try:
                print()
                pretty_print(es.nodes.info(node_id=arg, metric="settings", human=True, flat_settings=True), indent=2)
                print()
            except Exception:
                error()
        else:
            try:
                print()
                pretty_print(es.nodes.info(metric="settings", human=True, flat_settings=True), indent=2)
                print()
            except Exception:
                error()

    def complete_nodes_settings(self, text, line, begidx, endidx):
        return [i for i in nodelist() if i.startswith(text)]

    def do_nodes_hot_threads(self, arg):
        """
        Shows the current hot threads on each node in the cluster.
        $ nodes_hot_threads [threads_no] [cpu|wait|block] [node id]- the type to sample to see number of hot threads.
        $ nodes_hot_threads - show top 5 hot threads in cpu type for all nodes.
        """
        if arg:
            argv = arg.split()
            if len(argv) == 3:
                try:
                    print()
                    print(es.nodes.hot_threads(threads=argv[0], type=argv[1], node_id=argv[2]))
                    print()
                except Exception:
                    error()
            else:
                print()
                print("Please enter number of threads, type and node id.")
                print()
        else:
            try:
                print()
                print(es.nodes.hot_threads(threads="5", type="cpu", node_id="_all"))
            except Exception:
                error()

    def do_nodes_tasks(self, arg):
        """
        Show tasks currently executing on one or mode nodes in the cluster.
        $ nodes_tasks [task_id] - show info about particular task.
        $ nodes_tasks - retrieves all tasks currently running on all nodes in the cluster (default).
        """

        if arg:
            try:
                print()
                print(json.dumps(es.tasks.get(task_id=arg), indent=4))
                print()
            except Exception:
                error()
        else:
            try:
                print()
                print(es.cat.tasks(v=True, detailed=True, s="node"))
            except Exception:
                error()

    def do_nodes_tasks_by_action(self, arg):
        """
        Retrieves all tasks currently running on all nodes in the cluster filtered by action.
        eg: cluster*, indices*, *search, *bulk, *reindex etc.
        $ nodes_tasks_by_action cluster* - retrieves all cluster-related tasks running on all nodes.
        """
        if arg:
            argv = arg.split()
            if len(argv) == 1:
                try:
                    print()
                    pretty_print(es.tasks.list(detailed=True, group_by="nodes", actions=argv[0]), indent=2)
                    print()
                except Exception:
                    error()
            else:
                print()
                print("Please enter action name.")
                print()
        else:
            try:
                print()
                pretty_print(es.tasks.list(detailed=True, group_by="nodes"), indent=2)
                print()
            except Exception:
                error()

    def do_nodes_tasks_by_node(self, arg):
        """
        Retrieves all tasks currently running on specified nodes in the cluster.
        $ nodes_tasks_by_node [name|node_id] - retrieves all tasks running on node [node]
        """
        if arg:
            argv = arg.split()
            if len(argv) == 1:
                try:
                    print()
                    pretty_print(es.tasks.list(detailed=True, group_by="nodes", nodes=argv[0]), indent=2)
                    print()
                except Exception:
                    error()
            else:
                print()
                print("Please enter node name or id.")
                print()
        else:
            try:
                print()
                pretty_print(es.tasks.list(detailed=True, group_by="nodes"), indent=2)
                print()
            except Exception:
                error()

    def do_nodes_info_os(self, arg):
        """
        Retrieve node(s) information that concern the operating system.
        $ nodes_info_os [name|node_id] - show node os information.
        $ nodes_info_os - show os information for all the nodes (default).

          - os.refresh_interval_in_millis - refresh interval for the OS statistics.
          - os.name - name of the operating system (Linux / Windows / Mac OS X).
          - os.arch - name of the JVM architecture (amd64, x86).
          - os.version - version of the operating system.
          - os.available_processors - number of processors available to the Java virtual machine.
          - os.allocated_processors - the number of processors actually used to calculate thread
            pool size. This number can be set with the "processors" setting of a node and defaults
            to the number of processors reported by the OS. In both cases this number will never be
            larger than 32.
        """
        if arg:
            try:
                print()
                pretty_print(es.nodes.info(node_id=arg, metric="os", human=True, flat_settings=True), indent=2)
                print()
            except Exception:
                error()
        else:
            try:
                print()
                pretty_print(es.nodes.info(metric="os", human=True, flat_settings=True), indent=2)
                print()
            except Exception:
                error()

    def complete_nodes_info_os(self, text, line, begidx, endidx):
        return [i for i in nodelist() if i.startswith(text)]

    def do_nodes_info_process(self, arg):
        """
        Retrieve node(s) information that concern the current running ElasticSearch process.
        $ node_info_process [name|node_id] - show node ES process information.
        $ node_info_process - show ES process information for all the nodes (default).

          - process.refresh_intervel_in_millis - refresh interval for the process statistics.
          - process.id - process identifier (PID).
          - process.mlockall - indicates if the process address space has been successfully locked in memory.
        """
        if arg:
            try:
                print()
                pretty_print(es.nodes.info(node_id=arg, metric="process", human=True, flat_settings=True), indent=2)
                print()
            except Exception:
                error()
        else:
            try:
                print()
                pretty_print(es.nodes.info(metric="process", human=True, flat_settings=True), indent=2)
                print()
            except Exception:
                error()

    def complete_nodes_info_process(self, text, line, begidx, endidx):
        return [i for i in nodelist() if i.startswith(text)]

    def do_nodes_info_jvm(self, arg):
        """
        Show information about node JVM: GC collectors, arguments, heap, version etc.
        $ nodes_info_jvm [name|node_id] - info about one [node].
        $ nodes_info_jvm - info about all nodes.
        """
        if arg:
            try:
                print()
                pretty_print(es.nodes.info(node_id=arg, metric="jvm", human=True, flat_settings=True), indent=2)
                print()
            except Exception:
                error()
        else:
            try:
                print()
                pretty_print(es.nodes.info(metric="jvm", human=True, flat_settings=True), indent=2)
                print()
            except Exception:
                error()

    def complete_nodes_info_jvm(self, text, line, begidx, endidx):
        return [i for i in nodelist() if i.startswith(text)]

    def do_nodes_info_thread_pool(self, arg):
        """
        Show summary information about node thread pools.
        $ nodes_info_thread_pool [name|node_id] - info about one [node].
        $ nodes_info_thread_pool - info about all nodes.
        """
        if arg:
            try:
                print()
                pretty_print(es.nodes.info(node_id=arg, metric="thread_pool", human=True, flat_settings=True), indent=2)
                print()
            except Exception:
                error()
        else:
            try:
                print()
                pretty_print(es.nodes.info(metric="thread_pool", human=True, flat_settings=True), indent=2)
                print()
            except Exception:
                error()

    def complete_nodes_info_thread_pool(self, text, line, begidx, endidx):
        return [i for i in nodelist() if i.startswith(text)]

    def do_nodes_info_transport(self, arg):
        """
        Show information about transport address and port.
        $ nodes_info_transport [name|node_id] - info about one [node].
        $ nodes_info_transport - info about all nodes.
        """
        if arg:
            try:
                print()
                pretty_print(es.nodes.info(node_id=arg, metric="transport", human=True, flat_settings=True), indent=2)
                print()
            except Exception:
                error()
        else:
            try:
                print()
                pretty_print(es.nodes.info(metric="transport", human=True, flat_settings=True), indent=2)
                print()
            except Exception:
                error()

    def complete_nodes_info_transport(self, text, line, begidx, endidx):
        return [i for i in nodelist() if i.startswith(text)]

    def do_nodes_info_http(self, arg):
        """
        Show information about http address and port.
        $ nodes_info_http [name|node_id] - info about one [node].
        $ nodes_info_http - info about all nodes.
        """
        if arg:
            try:
                print()
                pretty_print(es.nodes.info(node_id=arg, metric="http", human=True, flat_settings=True), indent=2)
                print()
            except Exception:
                error()
        else:
            try:
                print()
                pretty_print(es.nodes.info(metric="http", human=True, flat_settings=True), indent=2)
                print()
            except Exception:
                error()

    def complete_nodes_info_http(self, text, line, begidx, endidx):
        return [i for i in nodelist() if i.startswith(text)]

    def do_nodes_info_plugins(self, arg):
        """
        Result will contain details about the loaded plugins and modules per node.
        $ node_info_plugins [node_id|name] - show [node] ES plugins information.
        $ node_info_plugins - show ES plugins information for all the nodes (default).

          - plugins.name - plugin name.
          - plugins.description - plugin description if any.
          - plugins.site - true if the plugin is a site plugin.
          - plugins.jvm - true if plugin is a plugin running in the JVM.
          - plugins.url - URL if the plugin is a site plugin.
        """
        if arg:
            try:
                print()
                pretty_print(es.nodes.info(node_id=arg, metric="plugins", human=True, flat_settings=True), indent=2)
                print()
            except Exception:
                error()
        else:
            try:
                print()
                pretty_print(es.nodes.info(metric="plugins", human=True, flat_settings=True), indent=2)
                print()
            except Exception:
                error()

    def complete_nodes_info_plugins(self, text, line, begidx, endidx):
        return [i for i in nodelist() if i.startswith(text)]

    def do_nodes_info_ingest(self, arg):
        """
        Result will contain details about the available processors per node.
        $ node_info_ingest [name|node_id] - show [node] ES ingest information.
        $ node_info_ingest - show ES ingest information for all the nodes (default).

          - processors.type - the processor type.
        """
        if arg:
            try:
                print()
                pretty_print(es.nodes.info(node_id=arg, metric="ingest", human=True, flat_settings=True), indent=2)
                print()
            except Exception:
                error()
        else:
            try:
                print()
                pretty_print(es.nodes.info(metric="ingest", human=True, flat_settings=True), indent=2)
                print()
            except Exception:
                error()

    def complete_nodes_info_ingest(self, text, line, begidx, endidx):
        return [i for i in nodelist() if i.startswith(text)]

    def do_nodes_info_indexing_buffer(self, arg):
        """
        Result will contain details about heap used for indexing process.
        $ node_info_indexing_buffer [name|node_id] - show [node] ES indexing heap information.
        $ node_info_indexing_buffer - show ES indexing heap information for all the nodes (default).

          - total_indexing_buffer - total heap allowed to be used to hold recently indexed documents before
            they must be written do disk. This size is a shared pool across all shards on this node, and is
            controlled by Indexing Buffer settings (indices.memory.index_buffer_size).
          - total_indexing_buffer_in_bytes - same as total_indexing_buffer but expressed in bytes.
        """
        if arg:
            try:
                print()
                pretty_print(es.nodes.info(node_id=arg, metric="indices", human=True, flat_settings=True))
                print()
            except Exception:
                error()
        else:
            try:
                print()
                pretty_print(es.nodes.info(metric="indices", human=True, flat_settings=True))
                print()
            except Exception:
                error()

    def complete_nodes_info_indexing_buffer(self, text, line, begidx, endidx):
        return [i for i in nodelist() if i.startswith(text)]

    def do_nodes_stats_indices(self, arg):
        """
        Show indices stats about size, document count, indexing and deletion times, search times,
        field cache size, merges and flushes.
        $ node_stats_indices [name|node_id] - show [node] ES indices stats.
        $ node_stats_indices - show ES indices stats for all the nodes (default).
        """
        if arg:
            try:
                print()
                pretty_print(es.nodes.stats(node_id=arg, metric="indices", human=True, level="node"))
                print()
            except Exception:
                error()
        else:
            try:
                print()
                pretty_print(es.nodes.stats(metric="indices", human=True, level="node"))
                print()
            except Exception:
                error()

    def complete_nodes_stats_indices(self, text, line, begidx, endidx):
        return [i for i in nodelist() if i.startswith(text)]

    def do_nodes_stats_fs(self, arg):
        """
        Show file system information, data path, free disk space, read/write stats.
        $ nodes_stats_fs [name|node_id] - show [node] ES fs stats.
        $ nodes_stats_fs - show node ES fs stats for all the nodes (default).

          - fs.timestamp - last time the file stores statistics have been refreshed.
          - fs.total.total_in_bytes - total size (in bytes) of all file stores.
          - fs.total.free_in_bytes - total number of unallocated bytes in all file stores.
          - fs.total.available_in_bytes - total number of bytes available to this Java virtual machine on all
            file stores.
          - fs.data - list of all file stores.
          - fs.data.path - path to the file store.
          - fs.data.mount - mount point of the file store (ex: /dev/sda2)
          - fs.data.type - type of the file store (ex: ext4)
          - fs.data.total_in_bytes - total size (in bytes) of the file store.
          - fs.data.free_in_bytes - total number of unallocated bytes in the file store.
          - fs.data.available_in_bytes - total number of bytes available to this Java virtual machine on this
            file store.
          - fs.data.spins - indicates if the store is backed by spinning storage.
            null means we cloud not determine it.
            true means the device possible spins.
            false means it does not (ex: solid-state disk)
          - fs.io_stats.devices - array of disk metrics for each device that is backing an Elasticsearch data path.
            These disk metrics are probed periodically and averages between the last probe and the current probe are
            computed.
          - fs.io_stats.devices.device_name - the Linux device name.
          - fs.io_stats.devices.operations - the total number of read and write operations for the device completed
            since starting Elasticsearch.
          - fs.io_stats.devices.read_operations - the total number of read operations for the device completed since
            starting Elasticsearch.
          - fs.io_stats.devices.write_operations - the total number of write operations for the device completed since
            starting Elasticsearch.
          - fs.io_stats.devices.read_kilobytes - the total number of kilobytes read for the device since starting
            Elasticsearch.
          - fs.io_stats.devices.write_kilobytes - the total number of kilobytes written for the device since starting
            Elasticsearch.
          - fs.io_stats.operations - the total number of read and write operations across all devices used by
            Elasticsearch completed since starting Elasticsearch.
          - fs.io_stats.read_operations - the total number of read operations for across all devices used by
            Elasticsearch completed since starting Elasticsearch.
          - fs.io_stats.write_operations - the total number of write operations across all devices used by
            Elasticsearch completed since starting Elasticsearch.
          - fs.io_stats.read_kilobytes - the total number of kilobytes read across all devices used by Elasticsearch
            since starting Elasticsearch.
          - fs.io_stats.write_kilobytes - the total number of kilobytes written across all devices used by Elasticsearch
            since starting Elasticsearch.
        """
        if arg:
            try:
                print()
                pretty_print(es.nodes.stats(node_id=arg, metric="fs", human=True, level="node"))
                print()
            except Exception:
                error()
        else:
            try:
                print()
                pretty_print(es.nodes.stats(metric="fs", human=True, level="node"))
                print()
            except Exception:
                error()

    def complete_nodes_stats_fs(self, text, line, begidx, endidx):
        return [i for i in nodelist() if i.startswith(text)]

    def do_nodes_stats_http(self, arg):
        """
        Show HTTP connection information.
        $ node_stats_http [name|node_id] - show [node] ES HTTP stats.
        $ node_stats_http - show ES HTTP stats for all the nodes (default).
        """
        if arg:
            try:
                print()
                pretty_print(es.nodes.stats(node_id=arg, metric="http", human=True, level="node"))
                print()
            except Exception:
                error()
        else:
            try:
                print()
                pretty_print(es.nodes.stats(metric="http", human=True, level="node"))
                print()
            except Exception:
                error()

    def complete_nodes_stats_http(self, text, line, begidx, endidx):
        return [i for i in nodelist() if i.startswith(text)]

    def do_nodes_stats_jvm(self, arg):
        """
        Show JVM stats, memory pool information, garbage collection, buffer pools, number of loaded/unloaded classes.
        $ node_stats_jvm [name|node_id] - show node ES JVM stats.
        $ node_stats_jvm - show ES JVM stats for all the nodes (default).
        """
        if arg:
            try:
                print()
                pretty_print(es.nodes.stats(node_id=arg, metric="jvm", human=True, level="node"))
                print()
            except Exception:
                error()
        else:
            try:
                print()
                pretty_print(es.nodes.stats(metric="jvm", human=True, level="node"))
                print()
            except Exception:
                error()

    def complete_nodes_stats_jvm(self, text, line, begidx, endidx):
        return [i for i in nodelist() if i.startswith(text)]

    def do_nodes_stats_os(self, arg):
        """
        Show operating system stats, load average, mem, swap.
        $ node_stats_os [name|node_id] - show [node] ES OS stats.
        $ node_stats_os - show ES OS stats for all the nodes (default).

          - os.timestamp - last time the operating system statistics have been refreshed.
          - os.cpu.percent - recent CPU usage for the whole system, or -1 if not supported.
          - os.cpu.load_average.1m - one-minute load average on the system (field is not present if one-minute load
            average is not available).
          - os.cpu.load_average.5m - five-minute load average on the system (field is not present if five-minute
            load average is not available).
          - os.cpu.load_average.15m - fifteen-minute load average on the system (field is not present if fifteen-minute
            load average is not available).
          - os.mem.total_in_bytes - total amount of physical memory in bytes.
          - os.mem.free_in_bytes - amount of free physical memory in bytes.
          - os.mem.free_percent - percentage of free memory.
          - os.mem.used_in_bytes - amount of used physical memory in bytes.
          - os.mem.used_percent - percentage of used memory.
          - os.swap.total_in_bytes - total amount of swap space in bytes.
          - os.swap.free_in_bytes - amount of free swap space in bytes.
          - os.swap.used_in_bytes - amount of used swap space in bytes.
          - os.cgroup.cpuacct.control_group - the cpuacct control group to which the Elasticsearch process belongs.
          - os.cgroup.cpuacct.usage_nanos - the total CPU time (in nanoseconds) consumed by all tasks in the same cgroup
            as the Elasticsearch process.
          - os.cgroup.cpu.control_group - the cpu control group to which the Elasticsearch process belongs.
          - os.cgroup.cpu.cfs_period_micros - the period of time (in microseconds) for how regularly all tasks in the
            same cgroup as the Elasticsearch process should have their access to CPU resources reallocated.
          - os.cgroup.cpu.cfs_quota_micros - the total amount of time (in microseconds) for which all tasks in the same
            cgroup as the Elasticsearch process can run during one period os.cgroup.cpu.cfs_period_micros.
          - os.cgroup.cpu.stat.number_of_elapsed_periods - the number of reporting periods (as specified by
            os.cgroup.cpu.cfs_period_micros) that have elapsed.
          - os.cgroup.cpu.stat.number_of_times_throttled - the number of times all tasks in the same cgroup as
            the Elasticsearch process have been throttled.
          - os.cgroup.cpu.stat.time_throttled_nanos - the total amount of time (in nanoseconds) for which all tasks in
            the same cgroup as the Elasticsearch process have been throttled.
        """
        if arg:
            try:
                print()
                pretty_print(es.nodes.stats(node_id=arg, metric="os", human=True, level="node"))
                print()
            except Exception:
                error()
        else:
            try:
                print()
                pretty_print(es.nodes.stats(metric="os", human=True, level="node"))
                print()
            except Exception:
                error()

    def complete_nodes_stats_os(self, text, line, begidx, endidx):
        return [i for i in nodelist() if i.startswith(text)]

    def do_nodes_stats_process(self, arg):
        """
        Show process statistics, memory consumption, cpu usage, open file descriptors.
        $ node_stats_process [name|node_id] - show [node] ES process stats.
        $ node_stats_process - show ES process stats for all the nodes (default).
        """
        if arg:
            try:
                print()
                pretty_print(es.nodes.stats(node_id=arg, metric="process", human=True, level="node"))
                print()
            except Exception:
                error()
        else:
            try:
                print()
                pretty_print(es.nodes.stats(metric="process", human=True, level="node"))
                print()
            except Exception:
                error()

    def complete_nodes_stats_process(self, text, line, begidx, endidx):
        return [i for i in nodelist() if i.startswith(text)]

    def do_nodes_stats_thread_pool(self, arg):
        """
        Show statistics about each thread pool, including current size, queue and rejected tasks.
        $ node_stats_thread_pool [name|node_id] - show [node] ES threads stats.
        $ node_stats_thread_pool - show ES threads stats for all the nodes (default).
        """
        if arg:
            try:
                print()
                pretty_print(es.nodes.stats(node_id=arg, metric="thread_pool", human=True, level="node"))
                print()
            except Exception:
                error()
        else:
            try:
                print()
                pretty_print(es.nodes.stats(metric="thread_pool", human=True, level="node"))
                print()
            except Exception:
                error()

    def complete_nodes_stats_thread_pool(self, text, line, begidx, endidx):
        return [i for i in nodelist() if i.startswith(text)]

    def do_nodes_stats_transport(self, arg):
        """
        Show statistics about send and received bytes in cluster communication.
        $ node_stats_transport [name|node_id] - show [node] ES transport stats.
        $ node_stats_transport - show ES transport stats for all the nodes (default).
        """
        if arg:
            try:
                print()
                pretty_print(es.nodes.stats(node_id=arg, metric="transport", human=True, level="node"))
                print()
            except Exception:
                error()
        else:
            try:
                print()
                pretty_print(es.nodes.stats(metric="transport", human=True, level="node"))
                print()
            except Exception:
                error()

    def complete_nodes_stats_transport(self, text, line, begidx, endidx):
        return [i for i in nodelist() if i.startswith(text)]

    def do_nodes_stats_breaker(self, arg):
        """
        Show statistics about the field data circuit breaker.
        $ node_stats_breaker [name|node_id] - show [node] ES breaker stats.
        $ node_stats_breaker - show ES transport stats for all the nodes (default).
        """
        if arg:
            try:
                print()
                pretty_print(es.nodes.stats(node_id=arg, metric="breaker", human=True, level="node"))
                print()
            except Exception:
                error()
        else:
            try:
                print()
                pretty_print(es.nodes.stats(metric="breaker", human=True, level="node"))
                print()
            except Exception:
                error()

    def complete_nodes_stats_breaker(self, text, line, begidx, endidx):
        return [i for i in nodelist() if i.startswith(text)]

    def do_nodes_stats_discovery(self, arg):
        """
        Show statistics about the discovery.
        $ node_stats_discovery [name|node_id] - show [node] ES discovery stats.
        $ node_stats_discovery - show ES discovery stats for all the nodes (default).
        """
        if arg:
            try:
                print()
                pretty_print(es.nodes.stats(node_id=arg, metric="discovery", human=True, level="node"))
                print()
            except Exception:
                error()
        else:
            try:
                print()
                pretty_print(es.nodes.stats(metric="discovery", human=True, level="node"))
                print()
            except Exception:
                error()

    def complete_nodes_stats_discovery(self, text, line, begidx, endidx):
        return [i for i in nodelist() if i.startswith(text)]

    def do_nodes_stats_ingest(self, arg):
        """
        Show statistics about ingest preprocessing.
        $ node_stats_ingest [name|node_id] - show [node] ES ingest stats.
        $ node_stats_ingest - show ES ingest stats for all the nodes (default).
        """
        if arg:
            try:
                print()
                pretty_print(es.nodes.stats(node_id=arg, metric="ingest", human=True, level="node"))
                print()
            except Exception:
                error()
        else:
            try:
                print()
                pretty_print(es.nodes.stats(metric="ingest", human=True, level="node"))
                print()
            except Exception:
                error()

    def complete_nodes_stats_ingest(self, text, line, begidx, endidx):
        return [i for i in nodelist() if i.startswith(text)]

    def do_nodes_stats_adaptive_selection(self, arg):
        """
        Show statistics about adaptive replica selection.
        $ node_stats_adaptive_selection [name|node_id] - show [node] ES adaptive replica selection stats.
        $ node_stats_adaptive_selection - show ES adaptive replica selection stats for all nodes (default).

          - outgoing_searches - the number of outstanding search requests from the node these stats are for to the
            keyed node.
          - avg_queue_size - the exponentially weighted moving average queue size of search requests on the keyed node.
          - avg_service_time_ns - the exponentially weighted moving average service time of search requests on the
            keyed node.
          - avg_response_time_ns - the exponentially weighted moving average response time of search requests on the
            keyed node.
          - rank - the rank of this node; used for shard selection when routing search requests.

        """
        if arg:
            try:
                print()
                pretty_print(es.nodes.stats(node_id=arg, metric="adaptive_selection", human=True, level="node"))
                print()
            except Exception:
                error()
        else:
            try:
                print()
                pretty_print(es.nodes.stats(metric="adaptive_selection", human=True, level="node"))
                print()
            except Exception:
                error()

    def complete_nodes_stats_adaptive_selection(self, text, line, begidx, endidx):
        return [i for i in nodelist() if i.startswith(text)]

    def do_nodes_cat_disk_space(self, arg):
        """
        Shows nodes available disk space.
        """
        try:
            print()
            print(es.cat.nodes(s="name", h="name,ip,id,diskTotal,diskUsed,diskAvail,diskUsedPercent", v=True))
        except Exception:
            error()

    def do_nodes_cat_id(self, arg):
        """
        Shows nodes uniq ids.
        """
        try:
            print()
            print(es.cat.nodes(s="name", h="name,id", full_id=True, v=True))
        except Exception:
            error()

    def do_nodes_cat_ports(self, arg):
        """
        Shows nodes bound ip, transport and http address.
        """
        try:
            print()
            print(es.cat.nodes(s="name", h="name,ip,port,http_address", v=True))
        except Exception:
            error()

    def do_nodes_cat_version(self, arg):
        """
        Shows nodes Elasticsearch version, build hash and running java version.
        """
        try:
            print()
            print(es.cat.nodes(s="name", h="name,ip,id,version,build,jdk", v=True))
        except Exception:
            error()

    def do_nodes_cat_heap(self, arg):
        """
        Shows nodes used and maximum configured heap.
        """
        try:
            print()
            print(es.cat.nodes(s="name", h="name,ip,id,heap.current,heap.percent,heap.max", v=True))
        except Exception:
            error()

    def do_nodes_cat_ram(self, arg):
        """
        Shows nodes used and total memory.
        """
        try:
            print()
            print(es.cat.nodes(s="name", h="name,ip,id,ram.current,ram.percent,ram.max", v=True))
        except Exception:
            error()

    def do_nodes_cat_filedesc(self, arg):
        """
        Shows nodes used and maximum number of file descriptors.
        """
        try:
            print()
            print(es.cat.nodes(s="name", h="name,ip,id,file_desc.current,file_desc.percent,file_desc.max", v=True))
        except Exception:
            error()

    def do_nodes_cat_load(self, arg):
        """
        Shows nodes recent system CPU usage.
        """
        try:
            print()
            print(es.cat.nodes(s="name", h="name,ip,id,cpu,load_1m,load_5m,load_15m", v=True))
        except Exception:
            error()

    def do_nodes_cat_uptime(self, arg):
        """
        Shows nodes uptime.
        """
        try:
            print()
            print(es.cat.nodes(s="name", h="name,ip,id,uptime", v=True))
        except Exception:
            error()

    def do_nodes_cat_role(self, arg):
        """
        Shows nodes role.
        - m - master eligible node.
        - d - data node.
        - i - ingest node.
        - - - coordinating node only.
        """
        try:
            print()
            print(es.cat.nodes(s="name", h="name,ip,id,node.role,master", v=True))
        except Exception:
            error()

    def do_nodes_cat_completion(self, arg):
        """
        Shows nodes size of completion.
        """
        try:
            print()
            print(es.cat.nodes(s="name", h="name,ip,id,completionSize", v=True))
        except Exception:
            error()

    def do_nodes_cat_fielddata_and_evictions(self, arg):
        """
        Shows used fielddata cache memory and evictions.
        """
        try:
            print()
            print(es.cat.nodes(s="name", h="name,ip,id,fielddataMemory,fielddataEvictions", v=True))
        except Exception:
            error()

    def do_nodes_cat_query_cache_and_evictions(self, arg):
        """
        Shows used query cache memory and evictions.
        """
        try:
            print()
            print(es.cat.nodes(s="name", h="name,ip,id,queryCacheMemory,queryCacheEvictions", v=True))
        except Exception:
            error()

    def do_nodes_cat_request_cache_and_evictions(self, arg):
        """
        Shows used request cache memory, evictions, hit and miss count.
        """
        try:
            print()
            print(es.cat.nodes(s="name",
                               h="name,ip,id,requestCacheMemory,requestCacheEvictions,requestCacheHitCount,"
                                 "requestCacheMissCount", v=True))
        except Exception:
            error()

    def do_nodes_cat_flush(self, arg):
        """
        Shows number of flushes and time spent in flush.
        """
        try:
            print()
            print(es.cat.nodes(s="name", h="name,ip,id,flushTotal,flushTotalTime", v=True))
        except Exception:
            error()

    def do_nodes_cat_get(self, arg):
        """
        Shows number of current and total get operations, time spent in gets and others.
        """
        try:
            print()
            print(es.cat.nodes(s="name",
                               h="name,ip,id,getCurrent,getTime,getTotal,getExistsTime,getExistsTotal,getMissingTime,"
                                 "getMissingTotal", v=True))
        except Exception:
            error()

    def do_nodes_cat_delete(self, arg):
        """
        Shows number of current and total delete operations, time spent in deletions.
        """
        try:
            print()
            print(es.cat.nodes(s="name",
                               h="name,ip,id,indexingDeleteCurrent,indexingDeleteTime,indexingDeleteTotal", v=True))
        except Exception:
            error()

    def do_nodes_cat_indexing(self, arg):
        """
        Shows number of current and total index operations, time spent in indexing.
        """
        try:
            print()
            print(es.cat.nodes(s="name",
                               h="name,ip,id,indexingIndexCurrent,indexingIndexTime,indexingIndexTotal,"
                                 "indexingIndexFailed", v=True))
        except Exception:
            error()

    def do_nodes_cat_merges(self, arg):
        """
        Shows number of current and total mege operations, time spent in merging.
        """
        try:
            print()
            print(es.cat.nodes(s="name",
                               h="name,ip,id,mergesCurrent,mergesCurrentDocs,mergesCurrentSize,mergesTotal,"
                                 "mergesTotalDocs,mergesTotalSize,mergesTotalTime", v=True))
        except Exception:
            error()

    def do_nodes_cat_refresh(self, arg):
        """
        Shows number of refreshes and time spent in refreshes.
        """
        try:
            print()
            print(es.cat.nodes(s="name", h="name,ip,id,refreshTotal,refreshTime", v=True))
        except Exception:
            error()

    def do_nodes_cat_script(self, arg):
        """
        Shows total script compilations and compiled scripts evicted from cache.
        """
        try:
            print()
            print(es.cat.nodes(s="name", h="name,ip,id,scriptCompilations,scriptCacheEvictions", v=True))
        except Exception:
            error()

    def do_nodes_cat_search(self, arg):
        """
        Shows open search contexts.
        """
        try:
            print()
            print(es.cat.nodes(s="name", h="name,ip,id,searchOpenContexts", v=True))
        except Exception:
            error()

    def do_nodes_cat_search_fetch(self, arg):
        """
        Shows current fetch phase operations and time spent in fetch phase.
        """
        try:
            print()
            print(es.cat.nodes(s="name", h="name,ip,id,searchFetchCurrent,searchFetchTime,searchFetchTotal", v=True))
        except Exception:
            error()

    def do_nodes_cat_search_query(self, arg):
        """
        Shows current query phase operations and time spent in query phase.
        """
        try:
            print()
            print(es.cat.nodes(s="name", h="name,ip,id,searchQueryCurrent,searchQueryTime,searchQueryTotal", v=True))
        except Exception:
            error()

    def do_nodes_cat_search_scroll(self, arg):
        """
        Shows current open scroll contexts and time scroll contexts held open.
        """
        try:
            print()
            print(es.cat.nodes(s="name", h="name,ip,id,searchScrollCurrent,searchScrollTime,searchScrollTotal", v=True))
        except Exception:
            error()

    def do_nodes_cat_segments(self, arg):
        """
        Shows number of segments and memory used by segments.
        """
        try:
            print()
            print(es.cat.nodes(s="name",
                               h="name,ip,id,segmentsCount,segmentsMemory,segmentsIndexWriterMemor,"
                                 "segmentsVersionMapMemory,fixedBitsetMemory", v=True))
        except Exception:
            error()

    def do_nodes_cat_suggest(self, arg):
        """
        Shows number current suggest operations and time spent in suggest.
        """
        try:
            print()
            print(es.cat.nodes(s="name", h="name,ip,id,suggestCurrent,suggestTime,suggestTotal", v=True))
        except Exception:
            error()

    def do_nodes_thread_pool_write(self, arg):
        """
        Show current settings and status of threads for write operations.
        """
        try:
            print()
            print(es.cat.thread_pool(v=True, thread_pool_patterns="write", s="node_name",
                                     h="node_name,name,type,active,size,queue,queue_size,rejected,largest,completed,"
                                       "min,max,keep_alive"))
        except Exception:
            error()

    def do_nodes_thread_pool_bulk(self, arg):
        """
        Show current settings and status of threads for bulk operations.
        """
        try:
            print()
            print(es.cat.thread_pool(v=True, thread_pool_patterns="bulk", s="node_name",
                                     h="node_name,name,type,active,size,queue,queue_size,rejected,largest,completed,"
                                       "min,max,keep_alive"))
        except Exception:
            error()

    def do_nodes_thread_pool_analyze(self, arg):
        """
        Show current settings and status of threads for analyze operations.
        """
        try:
            print()
            print(es.cat.thread_pool(v=True, thread_pool_patterns="analyze", s="node_name",
                                     h="node_name,name,type,active,size,queue,queue_size,rejected,largest,completed,"
                                       "min,max,keep_alive"))
        except Exception:
            error()

    def do_nodes_thread_pool_generic(self, arg):
        """
        Show current settings and status of threads for generic (e.g., background node discovery) operations.
        """
        try:
            print()
            print(es.cat.thread_pool(v=True, thread_pool_patterns="generic", s="node_name",
                                     h="node_name,name,type,active,size,queue,queue_size,rejected,largest,completed,"
                                       "min,max,keep_alive"))
        except Exception:
            error()

    def do_nodes_thread_pool_index(self, arg):
        """
        Show current settings and status of threads for index / delete operations.
        """
        try:
            print()
            print(es.cat.thread_pool(v=True, thread_pool_patterns="index", s="node_name",
                                     h="node_name,name,type,active,size,queue,queue_size,rejected,largest,completed,"
                                       "min,max,keep_alive"))
        except Exception:
            error()

    def do_nodes_thread_pool_search(self, arg):
        """
        Show current settings and status of threads for count / search / suggest operations.
        """
        try:
            print()
            print(es.cat.thread_pool(v=True, thread_pool_patterns="search", s="node_name",
                                     h="node_name,name,type,active,size,queue,queue_size,rejected,largest,completed,"
                                       "min,max,keep_alive"))
        except Exception:
            error()

    def do_nodes_thread_pool_get(self, arg):
        """
        Show current settings and status of threads for get operations.
        """
        try:
            print()
            print(es.cat.thread_pool(v=True, thread_pool_patterns="get", s="node_name",
                                     h="node_name,name,type,active,size,queue,queue_size,rejected,largest,completed,"
                                       "min,max,keep_alive"))
        except Exception:
            error()

    def do_nodes_thread_pool_percolate(self, arg):
        """
        Show current settings and status of threads for percolate operations.
        """
        try:
            print()
            print(es.cat.thread_pool(v=True, thread_pool_patterns="percolate", s="node_name",
                                     h="node_name,name,type,active,size,queue,queue_size,rejected,largest,completed,"
                                       "min,max,keep_alive"))
        except Exception:
            error()

    def do_nodes_thread_pool_snapshot(self, arg):
        """
        Show current settings and status of threads for snapshot / restore operations.
        """
        try:
            print()
            print(es.cat.thread_pool(v=True, thread_pool_patterns="snapshot", s="node_name",
                                     h="node_name,name,type,active,size,queue,queue_size,rejected,largest,completed,"
                                       "min,max,keep_alive"))
        except Exception:
            error()

    def do_nodes_thread_pool_warmer(self, arg):
        """
        Show current settings and status of threads for segment warm-up operations.
        """
        try:
            print()
            print(es.cat.thread_pool(v=True, thread_pool_patterns="warmer", s="node_name",
                                     h="node_name,name,type,active,size,queue,queue_size,rejected,largest,completed,"
                                       "min,max,keep_alive"))
        except Exception:
            error()

    def do_nodes_thread_pool_refresh(self, arg):
        """
        Show current settings and status of threads for refresh operations.
        """
        try:
            print()
            print(es.cat.thread_pool(v=True, thread_pool_patterns="refresh", s="node_name",
                                     h="node_name,name,type,active,size,queue,queue_size,rejected,largest,completed,"
                                       "min,max,keep_alive"))
        except Exception:
            error()

    def do_nodes_thread_pool_listener(self, arg):
        """
        Show current settings and status of threads for java client executing action operations.
        """
        try:
            print()
            print(es.cat.thread_pool(v=True, thread_pool_patterns="listener", s="node_name",
                                     h="node_name,name,type,active,size,queue,queue_size,rejected,largest,completed,"
                                       "min,max,keep_alive"))
        except Exception:
            error()

    def do_nodes_thread_pool_management(self, arg):
        """
        Show current settings and status of threads management operations.
        """
        try:
            print()
            print(es.cat.thread_pool(v=True, thread_pool_patterns="management", s="node_name",
                                     h="node_name,name,type,active,size,queue,queue_size,rejected,largest,completed,"
                                       "min,max,keep_alive"))
        except Exception:
            error()

    def do_nodes_thread_pool_force_merge(self, arg):
        """
        Show current settings and status of threads force merge / optimize operations.
        """
        try:
            print()
            print(es.cat.thread_pool(v=True, thread_pool_patterns="force_merge", s="node_name",
                                     h="node_name,name,type,active,size,queue,queue_size,rejected,largest,completed,"
                                       "min,max,keep_alive"))
        except Exception:
            error()

    def do_nodes_thread_pool_flush(self, arg):
        """
        Show current settings and status of threads flush operations.
        """
        try:
            print()
            print(es.cat.thread_pool(v=True, thread_pool_patterns="flush", s="node_name",
                                     h="node_name,name,type,active,size,queue,queue_size,rejected,largest,completed,"
                                       "min,max,keep_alive"))
        except Exception:
            error()

    def do_nodes_thread_pool_fetch_shard_started(self, arg):
        """
        Show current settings and status of threads starting shard operations.
        """
        try:
            print()
            print(es.cat.thread_pool(v=True, thread_pool_patterns="fetch_shard_started", s="node_name",
                                     h="node_name,name,type,active,size,queue,queue_size,rejected,largest,completed,"
                                       "min,max,keep_alive"))
        except Exception:
            error()

    def do_nodes_thread_pool_fetch_shard_store(self, arg):
        """
        Show current settings and status of threads storing shard operations.
        """
        try:
            print()
            print(es.cat.thread_pool(v=True, thread_pool_patterns="fetch_shard_store", s="node_name",
                                     h="node_name,name,type,active,size,queue,queue_size,rejected,largest,completed,"
                                       "min,max,keep_alive"))
        except Exception:
            error()


# elasticsearch exec-console
class Exec(cmd.Cmd):
    intro = "{0}\n### Entering to cluster execution menu!\n### For more information, type \"help\" or \"?\".\n{1}". \
        format(BColors.BOLD, BColors.ENDC)
    prompt = "es7:exec~$ "
    ruler = "-"
    doc_header = "Available commands (type: help <command>):"

    def default(self, line):
        """
        Called on an input line when the command prefix is not recognized.
        In that case we execute the line as Python code.
        """
        try:
            exec(line) in self._locals, self._globals
        except NameError:
            print("Command {0} not found.".format(line))
        except SyntaxError:
            print("Invalid command syntax.")
        except KeyboardInterrupt:
            print("Detected Ctrl+D. Exiting...")
        except Exception:
            error()

    def preloop(self):
        """
        Initialization before prompting user for commands.
        """
        cmd.Cmd.preloop(self)
        self._history = []
        self._locals = {}
        self._globals = {}

    def precmd(self, line):
        """
        This method is called after the line has been input but before
        it has been interpreted. If you want to modifdy the input line
        before execution (for example, variable substitution) do it here.
        """
        self._history += [line.strip()]
        return line

    def postloop(self):
        """
        Take care of any unfinished business.
        """
        cmd.Cmd.postloop(self)
        print("Exiting...")

    def postcmd(self, stop, line):
        """
        If you want to stop the console, return something that evaluates to true.
        If you want to do some post command processing, do it here.
        """
        return stop

    def emptyline(self):
        """
        Do nothing on empty line input.
        """
        pass

    def do_prompt(self, arg):
        """
        Change console prompt.
        $ prompt [new prompt] - set new prompt.
        """
        self.prompt = "{0}:~$ ".format(arg)

    def do_help(self, arg):
        """
        Get help on commands:
        'help' or '?' with no arguments prints a list of commands for which help is available
        'help <command>' or '? <command>' gives help on <command>
        """
        cmd.Cmd.do_help(self, arg)

    def do_history(self, arg):
        """
        Print a list of commands that have been entered into console.
        """
        print(self._history)

    def do_history_file(self, arg):
        """
        Print a list of commands that have been recorded into history file.
        $ history_file 10 - show last 10 commands.
        $ history_file - show all commands.
        """
        if arg:
            history_length = readline.get_current_history_length()
            for i in (range((history_length - int(arg)), history_length)):
                print(readline.get_history_item(i + 1))
        else:
            for i in range(readline.get_current_history_length()):
                print(readline.get_history_item(i + 1))

    def do_history_search(self, arg):
        """
        Search for [term] in history file.
        $ history_search [term]
        """
        for i in (range(readline.get_current_history_length())):
            if re.search(arg, str(readline.get_history_item(i + 1))):
                print(readline.get_history_item(i + 1))

    def do_clear(self, arg):
        """
        Clear the screen.
        """
        os.system("clear")

    def do_shell(self, line):
        """
        Pass command to a system shell when line begins with '!'
        """
        print("Running shell command: {0}\n".format(line))
        sub_cmd = subprocess.Popen(line, shell=True, stdout=subprocess.PIPE)
        output = sub_cmd.communicate()[0].decode("utf-8")
        print(output)
        self.last_output = output

    def do_echo(self, line):
        """
        Print the input, replacing '$out' with the output of the last shell command.
        $ echo $out - print last output for shell command.
        """
        print(line.replace("$out", self.last_output))

    def do_quit(self, arg):
        """
        Quits from the console.
        """
        return True

    def do_exit(self, arg):
        """
        Exits from the console.
        """
        return True

    def do_EOF(self, line):
        """
        Exit on system end of file character (Ctrl+D).
        """
        return True

    def do_leave(self, line):
        """
        Leave submenu.
        """
        return True

    def do_show(self, line):
        """Execute command in cluster information menu."""
        Show().onecmd(line)

    def complete_show(self, text, line, begidx, endidx):
        return [i for i in commandlist(Show()) if i.startswith(text)]

    # elasticsearch cluster-exec-console
    def do_cluster_reroute_retry_field_shards(self, arg):
        """
        Retries allocation of shards that are blocked due to too many subsequent allocation failures.
        """
        print()
        print(es.cluster.reroute(master_timeout="300s", retry_failed=True))
        print()

    def do_cluster_settings_transient(self, arg):
        """
        Update cluster wide specific settings.
        Resetting transient settings can be done by assigning a 'null' value. Strings must be in " ".
        $ cluster_settings_transient [setting] [value] - change cluster transient [setting] to new [value].
        """
        argv = arg.split()
        if len(argv) == 2:
            try:
                setme = '{{ "transient": {{ "{0}" : {1} }} }}'.format(str(argv[0]), str(argv[1]))
                print()
                print("Setting: " + setme)
                print()
                es.cluster.put_settings(body=setme, flat_settings=True, timeout="300s")
            except Exception:
                error()
        else:
            print()
            print("Please enter setting and its value.")
            print()

    def do_cluster_settings_persistent(self, arg):
        """
        Update cluster wide specific settings.
        Resetting persistent settings can be done by assigning a 'null' value. String must be in " ".
        $ cluster_settings_persistent [setting] [value] - change cluster persistent [setting] to new [value].
        """
        argv = arg.split()
        if len(argv) == 2:
            try:
                setme = '{{ "persistent": {{ "{0}" : {1} }} }}'.format(str(argv[0]), str(argv[1]))
                print()
                print("Setting: " + setme)
                print()
                print(es.cluster.put_settings(body=setme, flat_settings=True, timeout="300s"))
                print()
            except Exception:
                error()
        else:
            print()
            print("Please enter setting and its value.")
            print()

    # elasticsearch indices-exec-console
    def do_indices_settings(self, arg):
        """
        Change specific index level settings in real time.
        $ indices_settings [index] [setting] [value] - change [index] static or dynamic [setting] to new [value].
        """
        argv = arg.split()
        if len(argv) == 3:
            try:
                setme = '{{ "index": {{ "{0}" : {1} }} }}'.format(str(argv[1]), str(argv[2]))
                print()
                print("Setting: " + setme)
                print()
                print(es.indices.put_settings(index=argv[0], body=setme))
                print()
            except Exception:
                error()
        else:
            print()
            print("Please enter setting and its value.")
            print()

    def do_indices_refresh(self, arg):
        """
        Explicitly refresh one or more index, making all operations performed since last
        refresh available for search.
        $ indices_refresh [index] - perform refresh on [index].
        """
        if arg:
            try:
                print()
                print(es.indices.refresh(index=args))
                print()
            except Exception:
                error()
        else:
            print()
            print("Please enter the index name.")
            print()

    def complete_indices_refresh(self, text, line, begidx, endidx):
        return [i for i in indexlist() if i.startswith(text)]

    def do_indices_flush(self, arg):
        """
        Perform a normal flush, then add a generated unique marker (sync_id) to all shards.
        $ indices_flush [index] - preform a synced flush on [index].
        """
        if arg:
            try:
                print()
                print(es.indices.flush_synced(index=arg))
                print()
            except Exception:
                error()
        else:
            print()
            print("Please enter the index name.")
            print()

    def complete_indices_flush(self, text, line, begidx, endidx):
        return [i for i in indexlist() if i.startswith(text)]

    def do_indices_create(self, arg):
        """
        Create an empty index in Elasticsearch.
        $ indices_create [index] [number_of_shards] [number_of_replicas] - create [index].
        """
        argv = arg.split()
        if len(argv) == 3:
            try:
                setme = '{{ "settings": {{ "index": {{ "number_of_shards": {0}, "number_of_replicas": {1} }} }} }}' \
                    .format(argv[1], argv[2])
                print()
                print(es.indices.create(index=argv[0], timeout="300s", wait_for_active_shards="all", body=setme))
                print()
            except Exception:
                error()
        else:
            print()
            print("Please enter index, number of shards and replicas.")
            print()

    def do_indices_create_compressed(self, arg):
        """
        Create an empty index in Elasticsearch with best compression.
        $ indices_create_compressed [index] [number_of_shards] [number_of_replicas] - create [index] with
          best compression.
        """
        argv = arg.split()
        if len(argv) == 3:
            try:
                setme = '{{ "settings": {{ "index": {{ "number_of_shards": {0}, "number_of_replicas": {1}, ' \
                        '"codec": "best_compression" }} }} }}'.format(argv[1], argv[2])
                print()
                print(es.indices.create(index=argv[0], timeout="300s", wait_for_active_shards="all", body=setme))
                print()
            except Exception:
                error()
        else:
            print()
            print("Please enter index, number of shards and replicas.")
            print()

    def do_indices_split(self, arg):
        """
        Allows you to split an existing index into a new index with more primary shards.
        $ indices_split [index] [target] [shards] - splits an existing [index] into a new [target] index with more
          primary [shards].
        """
        argv = arg.split()
        if len(argv) == 3:
            try:
                setme = '{{ "settings": {{ "index": {{ "number_of_shards": {0} }} }} }}'.format(argv[2])
                print()
                print(es.indices.split(index=argv[0], target=argv[1], body=setme))
                print()
            except Exception:
                error()
        else:
            print()
            print("Please enter source index, target index and number of shards.")
            print()

    def complete_indices_split(self, text, line, begidx, endidx):
        return [i for i in indexlist() if i.startswith(text)]

    def do_indices_shrink(self, arg):
        """
        Allows you to split an existing index into a new index with more primary shards.
        $ indices_shrink [index] [target] [shards] - shrinks an existing [index] into a new [target] index with fewer
          primary [shards].
        """
        argv = arg.split()
        if len(argv) == 3:
            try:
                setme = '{{ "settings": {{ "index": {{ "number_of_shards": {0} }} }} }}'.format(argv[2])
                print()
                print(es.indices.shrink(index=argv[0], target=argv[1], body=setme))
                print()
            except Exception:
                error()
        else:
            print()
            print("Please enter source index, target index and number of shards.")
            print()

    def complete_indices_shrink(self, text, line, begidx, endidx):
        return [i for i in indexlist() if i.startswith(text)]

    def do_indices_templates_delete(self, arg):
        """
        Delete an index template by its name.
        $ indices_templates_delete [template] - delete [template].
        """
        if arg:
            try:
                print()
                print(es.indices.delete_template(name=arg, master_timeout="300s"))
                print()
            except Exception:
                error()
        else:
            print()
            print("Please enter template name to delete.")
            print()

    def do_indices_analyze_standard(self, arg):
        """
        Perform the analysis process on a text and return the tokens breakdown of the text.
        $ indices_analyze_standard you know for search
        """
        if arg:
            try:
                print()
                print(json.dumps(es.indices.analyze(body='{{ "analyzer": "standard", "text": "{0}" }}'.format(arg)),
                                 indent=4))
                print()
            except Exception:
                error()
        else:
            print()
            print("Please enter text to analyze.")
            print()

    def do_indices_analyze_simple(self, arg):
        """
        Perform the analysis process on a text and return the tokens breakdown of the text.
        $ indices_analyze_simple you know for search
        """
        if arg:
            try:
                print()
                print(json.dumps(es.indices.analyze(body='{{ "analyzer": "simple", "text": "{0}" }}'.format(arg)),
                                 indent=4))
                print()
            except Exception:
                error()
        else:
            print()
            print("Please enter text to analyze.")
            print()

    def do_indices_analyze_whitespace(self, arg):
        """
        Perform the analysis process on a text and return the tokens breakdown of the text.
        $ indices_analyze_whitespace you know for search
        """
        if arg:
            try:
                print()
                print(json.dumps(
                    es.indices.analyze(body='{{ "analyzer": "whitespace", "text": "{0}" }}'.format(arg)), indent=4))
                print()
            except Exception:
                error()
        else:
            print()
            print("Please enter text to analyze.")
            print()

    def do_indices_analyze_stop(self, arg):
        """
        Perform the analysis process on a text and return the tokens breakdown of the text.
        $ indices_analyze_stop you know for search
        """
        if arg:
            try:
                print()
                print(json.dumps(es.indices.analyze(body='{{ "analyzer": "stop", "text": "{0}" }}'.format(arg)),
                                 indent=4))
                print()
            except Exception:
                error()
        else:
            print()
            print("Please enter text to analyze.")
            print()

    def do_indices_analyze_keyword(self, arg):
        """
        Perform the analysis process on a text and return the tokens breakdown of the text.
        $ indices_analyze_keyword you know for search
        """
        if arg:
            try:
                print()
                print(
                    json.dumps(es.indices.analyze(body='{{ "analyzer": "keyword", "text": "{0}" }}'.format(arg)),
                               indent=4))
                print()
            except Exception:
                error()
        else:
            print()
            print("Please enter text to analyze.")
            print()

    def do_indices_analyze_fingerprint(self, arg):
        """
        Perform the analysis process on a text and return the tokens breakdown of the text.
        $ indices_analyze_fingerprint you know for search
        """
        if arg:
            try:
                print()
                print(json.dumps(
                    es.indices.analyze(body='{{ "analyzer": "fingerprint", "text": "{0}" }}'.format(arg)),
                    indent=4))
                print()
            except Exception:
                error()
        else:
            print()
            print("Please enter text to analyze.")
            print()

    def do_indices_reindex(self, arg):
        """
        Reindex all documents from one index to another.
        $ indices_reindex [src_index] [dst_index] - copy documents from the [src_index] into the [dst_index].
        """
        argv = arg.split()
        if len(argv) == 2:
            try:
                reindex = '{{ "source": {{ "index": "{0}" }}, "dest": {{ "index": "{1}" }} }}'.format(argv[0],
                                                                                                      argv[1])
                print()
                print("Executing: " + reindex)
                print()
                print(es.reindex(body=reindex, slices=8, wait_for_active_shards="all", wait_for_completion=False))
                print()
            except Exception:
                error()
        else:
            print()
            print("Please enter source and destination index.")
            print()

    def do_indices_clone(self, arg):
        """
        Clones an existing index.
        $ indices_clone [src_index] [dst_index] - clone [src_index] into the [dst_index].
        """
        argv = arg.split()
        if len(argv) == 2:
            try:
                es.indices.clone(index=argv[0], target=argv[1])
            except Exception:
                error()
        else:
            print()
            print("Please enter source and destination index.")
            print()

    def do_indices_number_of_replicas(self, arg):
        """
        Change the the number of replicas each primary shard has.
        $ indices_number_of_replicas [index] 0 - disable replication of [index].
        $ indices_number_of_replicas [index] 1 - enable replication of [index].
        """
        argv = arg.split()
        if len(argv) == 2:
            try:
                replicaset = '{{ "index": {{ "number_of_replicas": {0} }} }}'.format(argv[1])
                print()
                print("Setting: " + replicaset)
                print()
                print(es.indices.put_settings(index=argv[0], body=replicaset))
                print()
            except Exception:
                error()
        else:
            print()
            print("Please enter index and number of replicas.")
            print()

    def do_indices_auto_expand_replicas(self, arg):
        """
        Auto-expand the number of replicas based on number of available nodes. Set to a dash delimited
        lower and upper bound (e.g. 0-5) or use all for the upper bound (e.g. 0-all). Defaults to false.
        $ indices_auto_expand_replicas [index] [range] - change [index] auto-expand replicas to [range].
        """
        argv = arg.split()
        if len(argv) == 2:
            try:
                replica = '{{ "index": {{ "auto_expand_replicas": {0} }} }}'.format(argv[1])
                print()
                print("Setting: " + replica)
                print()
                print(es.indices.put_settings(index=argv[0], body=replica))
                print()
            except Exception:
                error()
        else:
            print()
            print("Please enter index and number of auto-expand replicas.")
            print()

    def do_indices_refresh_interval(self, arg):
        """
        How often to perform a refresh operation, which makes recent changes to the index visible to search.
        Defaults to 1s. Can be set to -1 to disable refresh.
        $ indices_refresh_interval [index] [value] - change <index> refresh interval to [value].
        """
        argv = arg.split()
        if len(argv) == 2:
            try:
                refresh = '{{ "index": {{ "refresh_interval": {0} }} }}'.format(argv[1])
                print()
                print("Setting: " + refresh)
                print()
                print(es.indices.put_settings(index=argv[0], body=refresh))
                print()
            except Exception:
                error()
        else:
            print()
            print("Please enter index and refresh value in seconds.")
            print()

    def do_indices_max_result_window(self, arg):
        """
        The maximum value of 'from+size' for searches to this index. Defaults to 10.000. Search request take
        heap memory and time proportional to 'from+size' and this limits that memory.
        $ indices_max_result_window [index] [value] - change [index] max result window to [value].
        """
        argv = arg.split()
        if len(argv) == 2:
            try:
                maxwin = '{{ "index": {{ "max_result_window": {0} }} }}'.format(argv[1])
                print()
                print("Setting: " + maxwin)
                print()
                print(es.indices.put_settings(index=argv[0], body=maxwin))
                print()
            except Exception:
                error()
        else:
            print()
            print("Please enter index and max result window value.")
            print()

    def do_indices_max_rescore_window(self, arg):
        """
        The maximum value of window_size for rescores in searches of this index. Defaults to
        'index.max_result_window' which defaults to 10.000. Search request take heap memory and time
        proportional to max(window_size, from+size) and this limits that memory.
        $ indices_max_rescore_window [index] [value] - change [index] max rescore window to [value].
        """
        argv = arg.split()
        if len(argv) == 2:
            try:
                maxwin = '{{ "index": {{ "max_rescore_window": {0} }} }}'.format(argv[1])
                print()
                print("Setting: " + maxwin)
                print()
                print(es.indices.put_settings(index=argv[0], body=maxwin))
                print()
            except Exception:
                error()
        else:
            print()
            print("Please enter index and max rescore window value.")
            print()

    def do_indices_blocks_read_only(self, arg):
        """
        Set to true to make the index and index metadata read only, false to allow writes and metadata changes.
        $ indices_blocks_read_only [index] [true|false] - make [index] metadata read only or read/write.
        """
        argv = arg.split()
        if len(argv) == 2:
            try:
                readonly = '{{ "index": {{ "blocks.read_only": {0} }} }}'.format(argv[1])
                print()
                print("Setting: " + readonly)
                print()
                print(es.indices.put_settings(index=argv[0], body=readonly))
                print()
            except Exception:
                error()
        else:
            print()
            print("Please enter index and Boolean value.")
            print()

    def do_indices_blocks_read_only_allow_delete(self, arg):
        """
        Similar to indices_blocks_read_only, but also allows deleting the index to make more resources available.
        Set to true to make the index and index metadata read only, false to allow writes and metadata changes.
        $ indices_blocks_read_only_allow_delete [index] [true|false] - make [index] metadata read only or read/write.
        """
        argv = arg.split()
        if len(argv) == 2:
            try:
                readonly = '{{ "index": {{ "blocks.read_only_allow_delete": {0} }} }}'.format(argv[1])
                print()
                print("Setting: " + readonly)
                print()
                print(es.indices.put_settings(index=argv[0], body=readonly))
                print()
            except Exception:
                error()
        else:
            print()
            print("Please enter index and boolean value.")
            print()

    def do_indices_blocks_read(self, arg):
        """
        Set to true to disable read operations against the index.
        $ indices_blocks_read [index] [true|false] - make [index] write only.
        """
        argv = arg.split()
        if len(argv) == 2:
            try:
                readonly = '{{ "index": {{ "blocks.read": {0} }} }}'.format(argv[1])
                print()
                print("Setting: " + readonly)
                print()
                print(es.indices.put_settings(index=argv[0], body=readonly))
                print()
            except Exception:
                error()
        else:
            print()
            print("Please enter index and boolean value.")
            print()

    def do_indices_blocks_write(self, arg):
        """
        Set to true to disable write operations against the index.
        $ indices_blocks_write [index] [true|false] - make [index] read only.
        """
        argv = arg.split()
        if len(argv) == 2:
            try:
                readonly = '{{ "index": {{ "blocks.write": {0} }} }}'.format(argv[1])
                print()
                print("Setting: " + readonly)
                print()
                print(es.indices.put_settings(index=argv[0], body=readonly))
                print()
            except Exception:
                error()
        else:
            print()
            print("Please enter index and boolean value.")
            print()

    def do_indices_blocks_metadata(self, arg):
        """
        Set to true to disable index metadata reads and writes.
        $ indices_blocks_metadata [index] [true|false] - block [index] metadata for writes and reads.
        """
        argv = arg.split()
        if len(argv) == 2:
            try:
                readonly = '{{ "index": {{ "blocks.metadata": {0} }} }}'.format(argv[1])
                print()
                print("Setting: " + readonly)
                print()
                print(es.indices.put_settings(index=argv[0], body=readonly))
                print()
            except Exception:
                error()
        else:
            print()
            print("Please enter index and boolean value.")
            print()

    def do_indices_search(self, arg):
        """
        Execute a search query and get back search hits that match the query.
        $ indices_search [index] *:* 10 - return 10 hits of query [index] in the Lucene query string syntax.
        """
        argv = arg.split()
        if len(argv) == 3:
            try:
                less(json.dumps(es.search(index=argv[0], q=argv[1], size=argv[2]), indent=2))
            except Exception:
                error()
        else:
            print()
            print("Please enter index, query and number of hits to return.")
            print()

    def do_indices_force_merge(self, arg):
        """
        The force merge API allows to force merging of one or more indices through an API.
        The merge relates to the number of segments a Lucene index holds within each shard.
        The force merge operation allows to reduce the number of segments by merging them.
        $ indices_forcemerge [index] [number] - merge [index] to [number] of segments.
        """
        argv = arg.split()
        if len(argv) == 2:
            try:
                print()
                print(es.indices.forcemerge(index=argv[0], max_num_segments=argv[1]))
                print()
            except Exception:
                error()
        else:
            print()
            print("Please provide index name nad number of segments.")
            print()

    def complete_indices_force_merge(self, text, line, begidx, endidx):
        return [i for i in indexlist() if i.startswith(text)]

    def do_indices_force_merge_only_expunge_deletes(self, arg):
        """
        Should the merge process only expunge segments with deletes in it. In Lucene, a document
        is not deleted from a segment, just marked as deleted. During a merge process of segments,
        a new segment is created that does not have those deletes. This command allows to only merge
        segments that have deletes.
        $ indices_force_merge_only_expunge_deletes [index] - merge only segments that have deletes.
        """
        if arg:
            try:
                print()
                print(es.indices.forcemerge(index=arg, only_expunge_deletes=True))
                print()
            except Exception:
                error()
        else:
            print()
            print("Please provide index name.")
            print()

    def complete_indices_force_merge_only_expunge_deletes(self, text, line, begidx, endidx):
        return [i for i in indexlist() if i.startswith(text)]

    def do_indices_aliases_delete(self, arg):
        """
        Delete specific alias.
        $ indices_aliases_delete [alias] [index] - delete [alias] for [index] (use _all for all indices or aliases).
        """
        argv = arg.split()
        if len(argv) == 2:
            try:
                print()
                print(es.indices.delete_alias(name=argv[0], index=argv[1]))
                print()
            except Exception:
                error()
        else:
            print()
            print("Please enter alias and index name.")
            print()

    def do_indices_aliases_create(self, arg):
        """
        Create an alias for a specific index/indices.
        $ indices_aliases_create [alias] [index] - create [alias] for [index] (use _all for all indices).
        """
        argv = arg.split()
        if len(argv) == 2:
            try:
                print()
                print(es.indices.put_alias(name=argv[0], index=argv[1]))
                print()
            except Exception:
                error()
        else:
            print()
            print("Please enter alias and index name.")
            print()

    def do_indices_delete(self, arg):
        """
        Delete an index in Elasticsearch.
        $ indices_delete [index] - delete the specified [index].
        """
        if arg:
            try:
                print()
                print(es.indices.delete(index=arg, master_timeout="300s"))
                print()
            except Exception:
                error()
        else:
            print()
            print("Missing index or a comma-separated list of indices to delete.")
            print()

    def complete_indices_delete(self, text, line, begidx, endidx):
        return [i for i in indexlist() if i.startswith(text)]

    def do_indices_close(self, arg):
        """
        Close an index to remove it's overhead from the cluster.
        Closed index is blocked for read/write operations.
        $ indices_close [index] - close the specified [index].
        """
        if arg:
            try:
                print()
                print(es.indices.close(index=arg, master_timeout="300s"))
                print()
            except Exception:
                error()
        else:
            print()
            print("Missing index or a comma-separated list of indices to close.")
            print()

    def complete_indices_close(self, text, line, begidx, endidx):
        return [i for i in indexlist() if i.startswith(text)]

    def do_indices_open(self, arg):
        """
        Open a closed index to make it available for search.
        $ indices_open [index] - open the specified [index].
        """
        if arg:
            try:
                print()
                print(es.indices.open(index=arg, master_timeout="300s"))
                print()
            except Exception:
                error()
        else:
            print()
            print("Missing index or a comma-separated list of indices to open.")
            print()

    def complete_indices_open(self, text, line, begidx, endidx):
        return [i for i in indexlist() if i.startswith(text)]

    def do_indices_freeze(self, arg):
        """
        Freezes an index. A frozen index has almost no overhead on the cluster (except for maintaining its metadata
        in memory) and is read-only.
        $ indices_freeze [index] - freezes an [index].
        """
        if arg:
            try:
                print()
                print(es.indices.freeze(index=arg, master_timeout="300s"))
                print()
            except Exception:
                error()
        else:
            print()
            print("Missing index or a comma-separated list of indices to freeze.")
            print()

    def complete_indices_freeze(self, text, line, begidx, endidx):
        return [i for i in indexlist() if i.startswith(text)]

    def do_indices_unfreeze(self, arg):
        """
        Unfreezes an index.
        $ indices_unfreeze [index] - Unfreezes an [index].
        """
        if arg:
            try:
                print()
                print(es.indices.unfreeze(index=arg, master_timeout="300s"))
                print()
            except Exception:
                error()
        else:
            print()
            print("Missing index or a comma-separated list of indices to unfreeze.")
            print()

    def complete_indices_unfreeze(self, text, line, begidx, endidx):
        return [i for i in indexlist() if i.startswith(text)]

    def do_indices_clear_cache(self, arg):
        """
        Clear either all caches or specific cached associated with one or more indices.
        $ indices_clear_cache  [index] - clear cache of the specified [index].
        $ indices_clear_cache - clear all caches (default)
        """
        if arg:
            try:
                print()
                print(es.indices.clear_cache(index=arg))
                print()
            except Exception:
                error()
        else:
            try:
                print()
                print(es.indices.clear_cache())
                print()
            except Exception:
                error()

    def complete_indices_clear_cache(self, text, line, begidx, endidx):
        return [i for i in indexlist() if i.startswith(text)]

    def do_indices_clear_cache_fielddata(self, arg):
        """
        Clear field data.
        $ indices_clear_cache_fielddata [index] - clear field data of the specified [index].
        $ indices_clear_cache_fielddata - clear field data of all indices (default).
        """
        if arg:
            try:
                print()
                print(es.indices.clear_cache(index=arg, fielddata=True))
                print()
            except Exception:
                error()
        else:
            try:
                print()
                print(es.indices.clear_cache(fielddata=True))
                print()
            except Exception:
                error()

    def complete_indices_clear_cache_fielddata(self, text, line, begidx, endidx):
        return [i for i in indexlist() if i.startswith(text)]

    def do_indices_clear_cache_query(self, arg):
        """
        Clear query caches.
        $ indices_clear_cache_query [index] - clear query caches of the specified [index].
        $ indices_clear_cache_query - clear query caches of all indices (default).
        """
        if arg:
            try:
                print()
                print(es.indices.clear_cache(index=arg, query=True))
                print()
            except Exception:
                error()
        else:
            try:
                print()
                print(es.indices.clear_cache(query=True))
                print()
            except Exception:
                error()

    def complete_indices_clear_cache_query(self, text, line, begidx, endidx):
        return [i for i in indexlist() if i.startswith(text)]

    def do_indices_clear_cache_recycler(self, arg):
        """
        Clear the recycler cache.
        $ indices_clear_cache_recycler [index] - clear the recycler cache of the specified [index].
        $ indices_clear_cache_recycler - clear the recycler cache of all indices (default).
        """
        if arg:
            try:
                print()
                print(es.indices.clear_cache(index=arg, recycler=True))
                print()
            except Exception:
                error()
        else:
            try:
                print()
                print(es.indices.clear_cache(recycler=True))
                print()
            except Exception:
                error()

    def complete_indices_clear_cache_recycler(self, text, line, begidx, endidx):
        return [i for i in indexlist() if i.startswith(text)]

    def do_indices_clear_cache_request(self, arg):
        """
        Clear the request cache.
        $ indices_clear_cache_request [index] - clear the request cache of the specified [index].
        $ indices_clear_cache request - clear the request cache of all indices (default).
        """
        if arg:
            try:
                print()
                print(es.indices.clear_cache(index=arg, request=True))
                print()
            except Exception:
                error()
        else:
            try:
                print()
                print(es.indices.clear_cache(request=True))
                print()
            except Exception:
                error()

    def complete_indices_clear_cache_request(self, text, line, begidx, endidx):
        return [i for i in indexlist() if i.startswith(text)]

    def do_indices_delete_all(self, arg):
        """
        Delete all indices in health status (red/yellow/green) from cluster.
        $ delete_all_indices [health] - delete all indices in [health] status from cluster.
        """
        if arg:
            try:
                indices_list = es.cat.indices(s="index", v=True, health=arg)
                indices_to_delete = es.cat.indices(s="index", health=arg, h="index", format="json")
                print()
                print(indices_list)
                print()
                confirm = input("Are you sure ? (yes/no): ").lower()
                print()
                if confirm == "yes":
                    total_size = len(indices_to_delete)
                    counter = 1
                    for indices in indices_to_delete:
                        idx = indices["index"]
                        print("Deleting: {0} [{1}/{2}]".format(idx, counter, total_size))
                        counter += 1
                        es.indices.delete(index=idx, master_timeout="300s", timeout="300s", ignore=[404])
                        print("Index {0} has been deleted.".format(idx))
                    print()
                else:
                    print()
                    print("Wise choice.")
                    print()
            except Exception:
                error()
        else:
            print()
            print("Please enter a health status ( green / yellow / red ).")
            print()

    # elasticsearch shards-exec-console
    def do_shards_allocate_replica_dry_run(self, arg):
        """
        Simulate allocate an unassigned replica shard to a node. Accepts the [index] for index name and
        [shard_number], and [dest_node] to allocate the shard to.
        $ shards_allocate_replica_dry_run [index] [numer] [dest_node] - simulate shard allocation.
        """
        argv = arg.split()
        if len(argv) == 3:
            try:
                alloc = '{{ "commands": [ {{ "allocate_replica": {{ "index": "{0}", "shard": {1}, "node": "{2}" ' \
                        '}} }} ] }}'.format(
                    str(argv[0]), str(argv[1]), str(argv[2]))
                print()
                print("Executing: " + alloc)
                print()
                pretty_print(es.cluster.reroute(body=alloc, dry_run=True, explain=True, metric="master_node"), indent=2)
                print()
            except Exception:
                error()
        else:
            print()
            print("Please enter index_name shard_number and dest_node.")
            print()

    def complete_shards_allocate_replica_dry_run(self, text, line, begidx, endidx):
        return [i for i in indexlist() if i.startswith(text)]

    def do_shards_allocate_replica(self, arg):
        """
        Allocate an unassigned replica shard to a node. Accepts the [index] for index name and
        [shard_number], and [dest_node] to allocate the shard to.
        $ shards_allocate_replica [index] [numer] [dest_node] - allocate shard [number] of [index] to [dest_node].
        """
        argv = arg.split()
        if len(argv) == 3:
            try:
                allocme = '{{ "commands": [ {{ "allocate_replica": {{ "index": "{0}", "shard": {1}, "node": "{2}" ' \
                          '}} }} ] }}'.format(
                    str(argv[0]), str(argv[1]), str(argv[2]))
                print()
                print("Executing: " + allocme)
                print()
                pretty_print(es.cluster.reroute(body=allocme, dry_run=False, explain=True, metric="master_node"),
                             indent=2)
                print()
            except Exception:
                error()
        else:
            print()
            print("Please enter index_name shard_number and dest_node.")
            print()

    def complete_shards_allocate_replica(self, text, line, begidx, endidx):
        return [i for i in indexlist() if i.startswith(text)]

    def do_shards_allocate_replica_cancel(self, arg):
        """
        Cancel allocation of a shard (or recovery). Accepts [index] and [shard] for index name and shard number,
        and [node] for the node to cancel the shard allocation on. This can be used to force resynchronization
        of existing replicas from the primary shard by cancelling and allowing them to be reinitialized through
        the standard recovery process.
        $ shards_allocate_replica_cancel [index] [numer] [dest_node] - cancel allocation of a replica shard.
        """
        argv = arg.split()
        if len(argv) == 3:
            try:
                cancel = '{{ "commands": [ {{ "cancel": {{ "index": "{0}", "shard": {1}, "node": "{2}" ' \
                         '}} }} ] }}'.format(
                    str(argv[0]), str(argv[1]), str(argv[2]))
                print()
                print("Executing: " + cancel)
                print()
                pretty_print(es.cluster.reroute(body=cancel, dry_run=False, explain=True, metric="master_node"),
                             indent=2)
                print()
            except Exception:
                error()
        else:
            print()
            print("Please enter index_name shard_number and dest_node.")
            print()

    def complete_shards_allocate_replica_cancel(self, text, line, begidx, endidx):
        return [i for i in indexlist() if i.startswith(text)]

    def do_shards_allocate_primary_cancel(self, arg):
        """
        By default only replica shard allocations can be cancelled (see shards_allocate_replica_cancel command).
        If it is necessary to cancel the allocation of a primary shard then the allow_primary flag must also be
        included in the request.
        $ shards_allocate_replica_cancel [index] [numer] [dest_node] - cancel allocation of a primary shard.
        """
        argv = arg.split()
        if len(argv) == 3:
            try:
                cancel = '{{ "commands": [ {{ "cancel": {{ "index": "{0}", "shard": {1}, "node": "{2}" ' \
                         '}} }} ] }}'.format(
                    str(argv[0]), str(argv[1]), str(argv[2]))
                print()
                print("Executing: " + cancel)
                print()
                pretty_print(es.cluster.reroute(body=cancel, dry_run=False, allow_primary=True, explain=True,
                                                metric="master_node"), indent=2)
                print()
            except Exception:
                error()
        else:
            print()
            print("Please enter index_name shard_number and dest_node.")
            print()

    def complete_shards_allocate_primary_cancel(self, text, line, begidx, endidx):
        return [i for i in indexlist() if i.startswith(text)]

    def do_shards_move_dry_run(self, arg):
        """
        Simulate move started shard from one node to another node. Accepts [index] for index name and
        [shard_number], [from_node] for the node to move the shard from, and [to_node] for the node to
        move the shard to.
        $ shards_move_dry_run [index] [number] [src_node] [dst_node] - simulate move shard <number> of [index]
          from [src_node] to [dst_node].
        """
        argv = arg.split()
        if len(argv) == 4:
            try:
                moveme = '{{ "commands": [ {{ "move": {{ "index": "{0}", "shard": {1}, "from_node": "{2}",' \
                         '"to_node": "{3}" }} }} ] }}'.format(str(argv[0]), str(argv[1]), str(argv[2]),
                                                              str(argv[3]))
                print()
                print("Executing: " + moveme)
                print()
                pretty_print(es.cluster.reroute(body=moveme, dry_run=True, explain=True, metric="master_node"),
                             indent=2)
                print()
            except Exception:
                error()
        else:
            print()
            print("Please enter index_name shard_number from_node to_node.")
            print()

    def complete_shards_move_dry_run(self, text, line, begidx, endidx):
        return [i for i in indexlist() if i.startswith(text)]

    def do_shards_move(self, arg):
        """
        Move started shard from one node to another node.  Accepts [index] for index name and
        [shard_number], [from_node] for the node to move the shard from, and [to_node] for the
        node to move the shard to.
        $ shards_move [index] [number] [src_node] [dst_node] - move shard [number] of [index]
          from [src_node] to [dst_node].
        """
        argv = arg.split()
        if len(argv) == 4:
            try:
                moveme = '{{ "commands": [ {{ "move": {{ "index": "{0}", "shard": {1}, "from_node": "{2}",' \
                         '"to_node": "{3}" }} }} ] }}'.format(str(argv[0]), str(argv[1]), str(argv[2]),
                                                              str(argv[3]))
                print()
                print("Executing: " + moveme)
                print()
                pretty_print(es.cluster.reroute(body=moveme, explain=True, metric="master_node"), indent=2)
                print()
            except Exception:
                error()
        else:
            print()
            print("Please enter index_name shard_number from_node to_node.")
            print()

    def complete_shards_move(self, text, line, begidx, endidx):
        return [i for i in indexlist() if i.startswith(text)]

    # elasticsearch nodes-exec-console
    def do_nodes_tasks_cancel(self, arg):
        """
        Cancel the task with specified task id (node_id:task_number).
        $ nodes_tasks_cancel [node_id:task_number] - cancel [task] on [node].
        """
        if arg:
            try:
                print()
                print(json.dumps(es.tasks.cancel(task_id=arg), indent=4))
                print()
            except Exception:
                error()
        else:
            print()
            print("Please enter node_id and task_number in format: node_id:task_number.")
            print()

    # elasticsearch search-exec-console
    def do_search_clear_scroll(self, arg):
        """
        Clear the scroll request created by specifying the scroll parameter to search.
        $ search_clear_scroll [scroll_id] - clear the <scroll_id>.
        """
        if arg:
            try:
                print()
                print(es.clear_scroll(scroll_id=arg))
                print()
            except Exception:
                error()
        else:
            print()
            print("Please enter a comma-separated list of scroll IDs to clear.")
            print()


if __name__ == "__main__":
    parser = argparse.ArgumentParser(prog="eshell", description="example: eshell elasticsearch.lan", epilog=":: ES7shell",
                                     add_help=True)
    parser.add_argument("host", nargs="?", help="elasticsearch IP or hostname (default: 127.0.0.1)",
                        default="127.0.0.1", type=str)
    parser.add_argument("-a", "--auth", dest="auth", help="use login and password", action="store_true")
    parser.add_argument("-p", "--port", dest="port", help="elasticsearch http port (default: 9200)", default="9200",
                        type=int)
    args = parser.parse_args()
    msg = (BColors.HEADER + "Connecting to elasticsearch server at address: {0:s}:{1:s}".format(args.host,
                                                                                                str(args.port)) +
           BColors.ENDC)
    try:
        # validate the host
        if check_hostname(args.host):
            print(msg)
            if isopen(args.host, args.port):
                host = args.host
            else:
                sys.exit(2)
        elif check_ip(args.host):
            print(msg)
            if isopen(args.host, args.port):
                host = args.host
            else:
                sys.exit(2)
        else:
            print(BColors.FAIL + "Wrong DNS or IP elasticsearch node address." + BColors.ENDC)
            sys.exit(2)
        # complement tabs
        if "libedit" in readline.__doc__:
            readline.parse_and_bind("bind ^I rl_complete")
        else:
            readline.parse_and_bind("tab: complete")
        # history file
        historyFile = check_env("~/.e7")[0]
        readline.set_history_length(5000)
        readline.read_history_file(historyFile)
        # session log
        logFile = check_env("~/.e7")[1]
        if os.path.isfile(logFile):
            size = os.path.getsize(logFile)
            if size >= 104857600:
                logging.handlers.RotatingFileHandler(filename=logFile, backupCount=10).doRollover()
        request_logger = logging.getLogger('urllib3')
        request_logger.setLevel(logging.DEBUG)
        request_file = logging.FileHandler(logFile)
        request_file.setLevel(logging.DEBUG)
        request_formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        request_file.setFormatter(request_formatter)
        request_logger.addHandler(request_file)
        response_logger = logging.getLogger('elasticsearch.trace')
        response_logger.setLevel(logging.DEBUG)
        response_file = logging.FileHandler(logFile)
        response_file.setLevel(logging.DEBUG)
        response_formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        response_file.setFormatter(response_formatter)
        response_logger.addHandler(response_file)
        request_logger.info(
            "### STARTING ELASTICSEARCH SHELL SESSION TO: {0:s}:{1:s}".format(args.host, str(args.port)))
        # configure elasticsearch client
        if args.auth:
            login = input("Login: ")
            password = getpass.getpass("Password: ")
            ssl_ca = input("Enter CA file path (or leave blank): ")
            if ssl_ca == "":
                ssl_ca = None
            ssl_crt = input("Enter CRT file path (or leave blank): ")
            if ssl_crt == "":
                ssl_crt = None
            ssl_key = input("Enter KEY file path (or leave blank): ")
            if ssl_key == "":
                ssl_key = None
            oauth = "{0}:{1}".format(login, password)
            ehost = "https://{0}@{1}:{2}".format(oauth, args.host, args.port)
            if ssl_ca is None:
                context = elasticsearch.connection.create_ssl_context()
                context.check_hostname = False
                context.verify_mode = ssl.CERT_NONE
                warnings.filterwarnings("ignore", message="Unverified HTTPS request")
                warnings.filterwarnings("ignore", message="When using `ssl_context`")
                es = elasticsearch.Elasticsearch([ehost], timeout=300, sniff_on_start=True,
                                                 sniff_on_connection_fail=True,
                                                 sniffer_timeout=60, retry_on_timeout=True, retry_on_status=True,
                                                 max_retries=99, ca_certs=ssl_ca, client_cert=ssl_crt,
                                                 client_key=ssl_key,
                                                 ssl_version=ssl.PROTOCOL_TLSv1_2, verify_certs=False,
                                                 ssl_show_warn=False,
                                                 ssl_context=context)
            else:
                es = elasticsearch.Elasticsearch([ehost], timeout=300, sniff_on_start=True,
                                                 sniff_on_connection_fail=True,
                                                 sniffer_timeout=60, retry_on_timeout=True, retry_on_status=True,
                                                 max_retries=99, ca_certs=ssl_ca, client_cert=ssl_crt,
                                                 client_key=ssl_key,
                                                 ssl_version=ssl.PROTOCOL_TLSv1_2)
        else:
            ehost = "http://{0}:{1}".format(args.host, args.port)
            es = elasticsearch.Elasticsearch([ehost], timeout=300, sniff_on_start=True, sniff_on_connection_fail=True,
                                             sniffer_timeout=60, retry_on_timeout=True, retry_on_status=True,
                                             max_retries=99)
        # run command line
        esconsole = ES()
        esconsole.cmdloop()
        # save history file
        atexit.register(readline.write_history_file, historyFile)
        request_logger.info(
            "### CLOSING ELASTICSEARCH SHELL SESSION TO: {0:s}:{1:s}...".format(args.host, str(args.port)))
    except KeyboardInterrupt:
        print("Exiting...")
        sys.exit(0)
    except Exception:
        error()
